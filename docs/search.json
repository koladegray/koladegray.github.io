[
  {
    "objectID": "blogs/2023-08-18-test/index.html",
    "href": "blogs/2023-08-18-test/index.html",
    "title": "Equivalence Tests Using {marginaleffects}",
    "section": "",
    "text": "First, a bit of background on the paper and the idea of hypothesizing that a variable “has no effect.”\nI remember sitting in a talk as a first-year graduate student, and the speaker said something like: “I expect no effect here, and, just as I expected, the difference is not statistically significant.” I was a little bit taken aback—of course, that’s not a compelling argument for a null effect. But I saw this approach taken again and again in published work.\nMy first publication was an AJPS article (Rainey 2014) explaining why this doesn’t work well and how to do it better.\nHere’s what I wrote in that paper:\n\nHypothesis testing is a powerful empirical argument not because it shows that the data are consistent with the research hypothesis, but because it shows that the data are inconsistent with other hypotheses (i.e., the null hypothesis). However, researchers sometimes reverse this logic when arguing for a negligible effect, showing only that the data are consistent with “no effect” and failing to show that the data are inconsistent with meaningful effects. When researchers argue that a variable has “no effect” because its confidence interval contains zero, they take no steps to rule out large, meaningful effects, making the empirical claim considerably less persuasive (Altman and Bland 1995; Gill 1999; Nickerson 2000).\n\nBut here’s a critical point, it’s impossible to reject every hypothesis except exactly no effect. Instead, the researcher must define a range of substantively “negligible” effects. The researcher can reject the null hypothesis that the effect falls outside this range of negligible effects. However, this requires a substantive judgement about those effects that are negligible and those that are not.\nHere’s what I wrote:\n\nResearchers who wish to argue for a negligible effect must precisely define the set of effects that are deemed “negligible” as well as the set of effects that are “meaningful.” This requires defining the smallest substantively meaningful effect, which I denote as \\(m\\). The definition must be debated by substantive scholars for any given context because the appropriate \\(m\\) varies widely across applications."
  },
  {
    "objectID": "blogs/2023-08-18-test/index.html#background-on-arguing-for-a-negligible-effect",
    "href": "blogs/2023-08-18-test/index.html#background-on-arguing-for-a-negligible-effect",
    "title": "Equivalence Tests Using {marginaleffects}",
    "section": "",
    "text": "First, a bit of background on the paper and the idea of hypothesizing that a variable “has no effect.”\nI remember sitting in a talk as a first-year graduate student, and the speaker said something like: “I expect no effect here, and, just as I expected, the difference is not statistically significant.” I was a little bit taken aback—of course, that’s not a compelling argument for a null effect. But I saw this approach taken again and again in published work.\nMy first publication was an AJPS article (Rainey 2014) explaining why this doesn’t work well and how to do it better.\nHere’s what I wrote in that paper:\n\nHypothesis testing is a powerful empirical argument not because it shows that the data are consistent with the research hypothesis, but because it shows that the data are inconsistent with other hypotheses (i.e., the null hypothesis). However, researchers sometimes reverse this logic when arguing for a negligible effect, showing only that the data are consistent with “no effect” and failing to show that the data are inconsistent with meaningful effects. When researchers argue that a variable has “no effect” because its confidence interval contains zero, they take no steps to rule out large, meaningful effects, making the empirical claim considerably less persuasive (Altman and Bland 1995; Gill 1999; Nickerson 2000).\n\nBut here’s a critical point, it’s impossible to reject every hypothesis except exactly no effect. Instead, the researcher must define a range of substantively “negligible” effects. The researcher can reject the null hypothesis that the effect falls outside this range of negligible effects. However, this requires a substantive judgement about those effects that are negligible and those that are not.\nHere’s what I wrote:\n\nResearchers who wish to argue for a negligible effect must precisely define the set of effects that are deemed “negligible” as well as the set of effects that are “meaningful.” This requires defining the smallest substantively meaningful effect, which I denote as \\(m\\). The definition must be debated by substantive scholars for any given context because the appropriate \\(m\\) varies widely across applications."
  },
  {
    "objectID": "blogs/2023-08-18-test/index.html#clark-and-golder-2006",
    "href": "blogs/2023-08-18-test/index.html#clark-and-golder-2006",
    "title": "Equivalence Tests Using {marginaleffects}",
    "section": "Clark and Golder (2006)",
    "text": "Clark and Golder (2006)\nClark and Golder (2006) offer a nice example of this sort of hypothesis. I’ll refer you there and to Rainey (2014) for a complete discussion of their idea, but I’ll motivate it briefly here.\nExplaining why a country might have only a few (i.e., two) parties, Clark and Golder write:\n\nFirst, it could be the case that the demand for parties is low because there are few social cleavages. In this situation, there would be few parties whether the electoral institutions were permissive or not. Second, it could be the case that the electoral system is not permissive. In this situation, there would be a small number of parties even if the demand for political parties were high. Only a polity characterized by both a high degree of social heterogeneity and a highly permissive electoral system is expected to produce a large number of parties. (p. 683)\n\nThus, they expect that electoral institutions won’t matter in socially homogenous systems. And they expect that social heterogeneity won’t matter in electoral systems that are not permissive."
  },
  {
    "objectID": "blogs/2023-08-18-test/index.html#reproducing-clark-and-golder-2006",
    "href": "blogs/2023-08-18-test/index.html#reproducing-clark-and-golder-2006",
    "title": "Equivalence Tests Using {marginaleffects}",
    "section": "Reproducing Clark and Golder (2006)",
    "text": "Reproducing Clark and Golder (2006)\nBefore computing their specific quantities of interest, let’s reproduce their regression model. Here’s their table that we’re trying to reproduce.\n\nAnd here’s a reproduction of their estimates using the cg2006 data from the {crdata} package on GitHub.11 Run ?crdata::cg2006 for detailed documentation of this data set.\n\n# load packages\nlibrary(tidyverse)\n\n# bind the comparisons together and plot"
  },
  {
    "objectID": "blogs/2023-09-29-hobrasio/index.html",
    "href": "blogs/2023-09-29-hobrasio/index.html",
    "title": "HOBRASIO: A Novel Therapy Regimen for Early Stage Androgenic Hair Loss",
    "section": "",
    "text": "At some points in their lifecycle, humans experience a distressing pattern of hair loss that is linked to multiple causes. Clinically, this condition is reviewed, diagnosed, and treated as ‘Alopecia.’ In many regions of the globe, alopecia is a common primary health complaint, constituting a huge portion of telemedicine services and point-of-care therapies. The pattern of hair loss in the population depends on different variables including genetic pool, healthcare efficiency index, common comorbidities, and multiple environmental triggers (Goldberg 2023). The psychosocial complications arising from this condition makes prompt diagnosis and management important determinant of prognosis.\n\n\n\nAlopecia Areata\n\nThis non-scaring form of hair loss is commonly described as Circular Hair Loss. Although it rarely occurs in clustered populations, it is considered the second most popular form of alopecia. Approximately, the lifetime prevalence of alopecia areata is pegged at 2% with an almost equal incidence on both men and women. Diagnosis for this form of alopecia is common before age 30.\n\n\n\n\n\n\nNote\n\n\n\nResearch studies have confirmed multiple etiologies for alopecia areata, with the most published studies concluding on the possibility of a hereditary component. People most commonly diagnosed with alopecia areata were likely to have a few comorbidities including thyroidal dysfunctions, autoimmune conditions, atopy, and vitiligo (Mysore, Chandrashekar, and Yepuri 2014).\n\n\nAlopecia areata presents as smooth, round patches with complete loss of hair and a retained follicular opening on the scalp and beard regions. Right on the edges of the affected region, short fragmented hair with thin shafts develops in isolated forms. Therapy delay may trigger a quick transition to ‘alopecia totalis’ –complete scalp balding or ‘alopecia universalis’ –hair loss on the body surface. The commonly adopted therapy protocols for alopecia areata involve a holistic modulation of the identified triggered for hair loss. Minoxidil, UVA therapy, and the experimental use of immunosuppressive drugs are common management options.\n\nAndrogenic Alopecia\n\nAlso described as ‘Patterned Hair Loss’, androgenic hair loss is considered the most commonly reported form of alopecia in both men and women. Data review from early studies published by the Southern Medical Journal and Dermatologic Surgery suggests that about half of androgenic alopecia male patients were diagnosed by age 50. Whereas, about 40% of androgenic alopecia female patients were diagnosed by age 70. In men, it is presented as a receding frontline with biphasic hair loss and shaft thinning. The presentation in women is slightly different with shaft thinning observed only at the crown as the anterior hairline remains preserved [(Qi and Garza 2014; Strazzulla et al. 2018)]. In many diagnosed cases, symptoms first occur at puberty ad progress slowly until the hair loss pattern becomes noticeable.\nA diagnosis for androgenic alopecia includes a review of clinical history, family history, and pattern of symptom presentation. Many times, androgenic alopecia transitions into complete baldness in men, however, this transition is rare in female patients. Adopted therapy protocols for this condition include the recent, FDA-approved medication, Minoxidil, commercially retailed as Rogaine. Other medications including Finasteride are considered as off-label therapy options for androgenic alopecia.\n\nDiffuse Alopecia Forms\n\nUnlike the forms of alopecia mentioned already, this group of alopecia forms affects the scalp uniformly. In acute telogen effluvium, hair loss can persist for about 6 months, with shedding triggers expressed 2-4 months earlier. Diffuse alopecia forms are of multiple etiologies. The most common etiologies linked with conformed cases of this condition include endocrine diseases, thyroidal dysfunctions, malnutrition, malignancies, and stress. Once the trigger pattern is initiated, about 20-50% of the scalp hairs are induced to progress through the telogen phase until they are completely lost.\n\n\n\n\n\n\nEpidemiological Data\n\n\n\nNormally, only about 5 - 10% of hairs enter the telogen phase. The increased transition to the telogen phase experienced by telogen effluvium patients can cause complete balding.\n\n\nIn anagen effluvium, hair shedding is replaced with hair breakage. The cortex cells of the hair follicles and other epidermal structures with a high mitotic division rate are most susceptible to this breakage effect. Radiation therapy and chemotherapy are widely studies causes of this formed of diffused hair loss. Within 4 weeks, hair loss becomes noticeable with over 80% of the scalp hair is already affected. Termination of the trigger factor has shown a noticeable reduction in hair breakage. Minoxidil remains the most promising therapy option for anagen effluvium."
  },
  {
    "objectID": "blogs/2023-09-29-hobrasio/index.html#hair-loss-in-a-lifecycle",
    "href": "blogs/2023-09-29-hobrasio/index.html#hair-loss-in-a-lifecycle",
    "title": "HOBRASIO: A Novel Therapy Regimen for Early Stage Androgenic Hair Loss",
    "section": "",
    "text": "At some points in their lifecycle, humans experience a distressing pattern of hair loss that is linked to multiple causes. Clinically, this condition is reviewed, diagnosed, and treated as ‘Alopecia.’ In many regions of the globe, alopecia is a common primary health complaint, constituting a huge portion of telemedicine services and point-of-care therapies. The pattern of hair loss in the population depends on different variables including genetic pool, healthcare efficiency index, common comorbidities, and multiple environmental triggers (Goldberg 2023). The psychosocial complications arising from this condition makes prompt diagnosis and management important determinant of prognosis.\n\n\n\nAlopecia Areata\n\nThis non-scaring form of hair loss is commonly described as Circular Hair Loss. Although it rarely occurs in clustered populations, it is considered the second most popular form of alopecia. Approximately, the lifetime prevalence of alopecia areata is pegged at 2% with an almost equal incidence on both men and women. Diagnosis for this form of alopecia is common before age 30.\n\n\n\n\n\n\nNote\n\n\n\nResearch studies have confirmed multiple etiologies for alopecia areata, with the most published studies concluding on the possibility of a hereditary component. People most commonly diagnosed with alopecia areata were likely to have a few comorbidities including thyroidal dysfunctions, autoimmune conditions, atopy, and vitiligo (Mysore, Chandrashekar, and Yepuri 2014).\n\n\nAlopecia areata presents as smooth, round patches with complete loss of hair and a retained follicular opening on the scalp and beard regions. Right on the edges of the affected region, short fragmented hair with thin shafts develops in isolated forms. Therapy delay may trigger a quick transition to ‘alopecia totalis’ –complete scalp balding or ‘alopecia universalis’ –hair loss on the body surface. The commonly adopted therapy protocols for alopecia areata involve a holistic modulation of the identified triggered for hair loss. Minoxidil, UVA therapy, and the experimental use of immunosuppressive drugs are common management options.\n\nAndrogenic Alopecia\n\nAlso described as ‘Patterned Hair Loss’, androgenic hair loss is considered the most commonly reported form of alopecia in both men and women. Data review from early studies published by the Southern Medical Journal and Dermatologic Surgery suggests that about half of androgenic alopecia male patients were diagnosed by age 50. Whereas, about 40% of androgenic alopecia female patients were diagnosed by age 70. In men, it is presented as a receding frontline with biphasic hair loss and shaft thinning. The presentation in women is slightly different with shaft thinning observed only at the crown as the anterior hairline remains preserved [(Qi and Garza 2014; Strazzulla et al. 2018)]. In many diagnosed cases, symptoms first occur at puberty ad progress slowly until the hair loss pattern becomes noticeable.\nA diagnosis for androgenic alopecia includes a review of clinical history, family history, and pattern of symptom presentation. Many times, androgenic alopecia transitions into complete baldness in men, however, this transition is rare in female patients. Adopted therapy protocols for this condition include the recent, FDA-approved medication, Minoxidil, commercially retailed as Rogaine. Other medications including Finasteride are considered as off-label therapy options for androgenic alopecia.\n\nDiffuse Alopecia Forms\n\nUnlike the forms of alopecia mentioned already, this group of alopecia forms affects the scalp uniformly. In acute telogen effluvium, hair loss can persist for about 6 months, with shedding triggers expressed 2-4 months earlier. Diffuse alopecia forms are of multiple etiologies. The most common etiologies linked with conformed cases of this condition include endocrine diseases, thyroidal dysfunctions, malnutrition, malignancies, and stress. Once the trigger pattern is initiated, about 20-50% of the scalp hairs are induced to progress through the telogen phase until they are completely lost.\n\n\n\n\n\n\nEpidemiological Data\n\n\n\nNormally, only about 5 - 10% of hairs enter the telogen phase. The increased transition to the telogen phase experienced by telogen effluvium patients can cause complete balding.\n\n\nIn anagen effluvium, hair shedding is replaced with hair breakage. The cortex cells of the hair follicles and other epidermal structures with a high mitotic division rate are most susceptible to this breakage effect. Radiation therapy and chemotherapy are widely studies causes of this formed of diffused hair loss. Within 4 weeks, hair loss becomes noticeable with over 80% of the scalp hair is already affected. Termination of the trigger factor has shown a noticeable reduction in hair breakage. Minoxidil remains the most promising therapy option for anagen effluvium."
  },
  {
    "objectID": "blogs/2023-09-29-hobrasio/index.html#pathophysiology-of-androgenic-alopecia",
    "href": "blogs/2023-09-29-hobrasio/index.html#pathophysiology-of-androgenic-alopecia",
    "title": "HOBRASIO: A Novel Therapy Regimen for Early Stage Androgenic Hair Loss",
    "section": "Pathophysiology of Androgenic Alopecia",
    "text": "Pathophysiology of Androgenic Alopecia\nAndrogenic alopecia is perhaps the most discussed alopecia form in the medical world. Many studies and clinical surveys have been conducted to understand its etiologies and disease course. Globally, there is a race distribution pattern on the incidence of androgenic alopecia. It is commonly diagnosed in the White population, followed by the Asian, African Americans, Native Americans, and Eskimos.\nIn a normal hair growth cycle, activation of the androgen receptors shortens the growth phase of each hair strand. Factors that directly modify the activation ate of this process present an overbearing effect on hair development. In androgenic alopecia, the activation trigger is excessively presented, leading to follicular miniaturization as the growth phase significantly shortens. Hair shafts produced becomes thin, short, and weakly penetrate through the epidermis. In this form, the strands are shed off easily. Hair loss occurs bi-temporarily, starting at the anterior hairline progressively moves over the scalp. At the vertex scalp, hair loss begins centrally and radiates outwards in all directions. Although hair loss is patterned, the site of hair loss is affected differently. In some men, balding is more prominent at the front, and in others, at the crown.\n\nConventional Therapy Methods\nConventionally, many forms of alopecia are treated with the same therapy protocol. In androgenic alopecia, management plans are directed at combatting the excessive activation of the androgenic receptors. This attempt to normalize the length of the growth phase requires extensive clinical monitoring, and many times a multi-therapy approach. The conventional therapy currently available struggles to directly reduce the rate of follicular miniaturization and promote hair replacement.\n\n\n\n\n\n\nPrescription Data\n\n\n\nCurrent trends in prescription data suggests that the FDA-approved drugs, topical Minoxidil and Finasteride are the most prescribed medications for androgenic alopecia.\n\n\nTopical minoxidil is presented in different dosage strengths and is available over-the-counter. This option requires a 4 to 6-month blind administration before an improvement is expected. As the period elapses, a comprehensive clinical review is conducted to determine modifications. Patients struggle with adherence and many times, this leads to therapy failure. Many research studies suggest the use of high-strength topical minoxidil formulation on a short therapy course.\nMinoxidil, as a potassium channel blocker improves blood vessel dilation. This action triggers the circulation of more oxygen, blood, and nutrients to the hair follicles. A rich supply of these components reportedly promotes the anagen phase and corrects alopecia in all its forms. Finasteride is another medication conventionally used in alopecia therapy regimens. It is commonly prescribed as a 1 mg daily regimen. As a 5 alpha-reductase type 2 inhibitor, this drug has shown significant efficacy in improving hair growth at the vertex [(Piraccini et al. 2021; Libecco and Bergfeld 2004)]. In female alopecia patients, finasteride has however shown inconsistent results. This, in parts, explains why it is considered contraindicated in females.\nOther drugs used in the off-label management of alopecia forms include Dutasteride, Cyproterone, and oral antiandrogens including spironolactone, prostaglandin analogs including latanoprost. Surgical options including hair transplant and laser treatment. These non-drug therapy options are also considered effective. Many patients opt for these as they are short-course therapies and are cosmetically satisfactory."
  },
  {
    "objectID": "blogs/2023-09-29-hobrasio/index.html#considering-hobrasio-as-a-novel-integrative-therapy-option",
    "href": "blogs/2023-09-29-hobrasio/index.html#considering-hobrasio-as-a-novel-integrative-therapy-option",
    "title": "HOBRASIO: A Novel Therapy Regimen for Early Stage Androgenic Hair Loss",
    "section": "Considering HOBRASIO as a Novel Integrative Therapy Option",
    "text": "Considering HOBRASIO as a Novel Integrative Therapy Option\nCurrently, the therapy options available for the management of alopecia forms produce inconsistent results. To a large part, the long-course drug therapies do not guarantee recovery, as their results cannot be easily reproductive in a patient population. Novel management methods using combination therapy options are quickly gaining traction in the medical community. These methods involve the combination of proven conventional and new therapies to rapidly improve hair growth or slow down hair loss. In addition to their effectiveness, these methods have shown considerable advantages in safety, skin compatibility, and result consistency.\nThe Hybrid Object Rejuvenation (HOBRASIO) option provides an evidence-based therapy for alopecia forms by combining different rejuvenation methods. This innovation improves hair growth in both gender and poses no medical threat to the patients. Although this method is new, there exists much research backing its usefulness in modern cosmetology.\n\n\n\n\n\n\nNote\n\n\n\nIn a 2016 review published by the Journal of Cosmetic and Laser Therapy, researchers recommended the use of combined therapy options in a same-day management model. Studies like this explore the possibilities and provide scientific backing for novel dermatology treatments like HOBRASIO\n\n\nIn the management of alopecia forms, HOBRASIO combines several proven strategies in a single therapy regimen. This innovation secures optimal therapy effects for epidermal rejuvenation. In addition to its regenerative effect on follicles, this novel therapy option also provides soft tissue augmentation and skin rejuvenation effects. Unlike in conventional management with fixed therapy modalities for alopecia, HOBRASIO combines different options within the limits of safety, for different skin types. This single approach makes it effective in promoting hair replacement at the vertex or the scalp. Patients are guaranteed a consistent result with a short-course therapy and no adherence problems."
  },
  {
    "objectID": "blogs/2023-09-29-hobrasio/index.html#hobrasio-regimen-for-alopecia-forms",
    "href": "blogs/2023-09-29-hobrasio/index.html#hobrasio-regimen-for-alopecia-forms",
    "title": "HOBRASIO: A Novel Therapy Regimen for Early Stage Androgenic Hair Loss",
    "section": "Hobrasio Regimen For Alopecia Forms",
    "text": "Hobrasio Regimen For Alopecia Forms\nAs a hybrid cosmetic therapy approach, HOBRASIO explores the combination of Minoxidil, low laser therapy, and Micro-needling for epidermal and superficial dermal problems. Alopecia falls right into this category. A combination of these three therapies into a single regimen triggers physiological modifications that solve alopecia. Combining these invasive procedures produces a desired clinical outcome that is considered cosmetically satisfactory. Early initiation of treatment can also effectively stop the transition to ‘alopecia universalis’ or ‘alopecia totalis.’\n\nMicro-needling\n\nMicro-needling is a relatively new therapy option in modern cosmetology. However, since its introduction in the early 90s, micro-needling has been used for different dermatological problems including skin rejuvenation, acne scarring, melisma, and surgical scar repair (Fertig et al. 2017). This minimally invasive procedure involves the use of multiple fine needles to create micro-punctures in the skin. This action triggers a physiologic cascade that triggers vascularization and the release of growth factors.\nThese growth factors initiate the rapid formation of collagen and elastin. In its use for alopecia, micro-needling triggers the release of platelet-derived growth factors and epidermal factors that activate the hair bulge. Proteins releases in this cascade also stimulate dermal stems cells and subsequent hair formation.\n\n\n\n\n\n\nNote\n\n\n\nIn a 2014 case study published by the Journal of Cutaneous and Anesthetic Surgery, a group of researchers demonstrated how micro-needling can effectively treat alopecia forms.\n\n\n\nLow Laser Therapy\n\nLow laser therapy is an innovative approach in modern dermatology that explores the physics of photons (particles of Light) for epidermal rejuvenation. Generally, this option utilizes low-intensity light at the red or near-infrared wavelength to alter the physiology of the epidermal cells (Yoon et al. 2021). In a large part, the precise mechanism of action of low laser therapy in hair replacement has not yet been established. However, multiple research studies suggest that low laser stimulates the anagen re-entry of telogen hair follicles.\nBy modifying the normal cycle of hair growth, the low laser stimulates the increase in hair growth rate, hair density, and diameter. Hair shedding decreases and the primary symptoms of alopecia clinically resolve.\n\n\n\n\n\n\nImportant\n\n\n\nIn 2007, the FDA approved the first Low laser device for use as a safe option for the treatment of alopecia. Since then, clinicians have increasingly recommended low laser therapy for many alopecia patients\n\n\n\nMinoxidil\n\nMinoxidil was originally developed as an anti-hypertensive. Post-market surveillance data suggested that this drug triggers hypertrichosis –excessive hair growth. Subsequently, topical formulations of minoxidil were developed and re-introduced for the treatment of alopecia. For several decades, minoxidil topical formulations have served primary purposes in hair growth therapies.\n\n\n\n\n\n\nClinicians Should Note\n\n\n\nDespite its wide application today, the exact mechanism of action of minoxidil for hair regeneration remain unestablished\n\n\nResearch studies have however postulated different hypotheses for this action. Minoxidil plays a key role in cell proliferation at the early stages.\nMinoxidil sulfate, a metabolite of minoxidil has also been proposed to be involved in the hair rejuvenation effects of minoxidil [(Suchonwanit, Thammarucha, and Leerunyakul 2019; Randolph and Tosti 2021; Villani et al. 2021)]. Minoxidil also stimulates prostaglandin E production in a cascade of reactions that ends with the stimulation of the hair follicles. This triggers the continuous growth of hair as the growth stage becomes elongated. Numerous clinical trials have been conducted to prove the efficacy of minoxidil at different concentrations for the treatment of androgenic alopecia."
  },
  {
    "objectID": "blogs/2023-09-29-hobrasio/index.html#final-thoughts",
    "href": "blogs/2023-09-29-hobrasio/index.html#final-thoughts",
    "title": "HOBRASIO: A Novel Therapy Regimen for Early Stage Androgenic Hair Loss",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nAlopecia forms have been consistently linked with increased risk of psychosocial complications in many patients. Uncontrolled air loss can trigger mild episodes of anxiety and depression as the patient desperately searches for effective therapy. HOBRASIO provides a comprehensive therapy approach for alopecia. The combined treatment options stimulate hair growth and also significantly reduces shedding. Compared with other treatments available today, HOBRASIO produces the desired clinical outcome within the limit of biological safety."
  },
  {
    "objectID": "blogs/2023-9-18-direct-library-preparation/index.html",
    "href": "blogs/2023-9-18-direct-library-preparation/index.html",
    "title": "Direct Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing",
    "section": "",
    "text": "Cell culture and tissue studies are becoming important in genomics and human biology. Despite the wide innovations in the field of cell studies, clinical results and experimental reviews from cell-based examinations are still largely tilted towards the conventional assumption that all cells derived from cultures and tissues are completely homogeneous.\nHow then should scientists study biological heterogeneity? Most importantly, how should they study the inherent properties of a single cell as an offshoot of the genome?"
  },
  {
    "objectID": "blogs/2023-9-18-direct-library-preparation/index.html#cell-sequencing-processes-and-studies",
    "href": "blogs/2023-9-18-direct-library-preparation/index.html#cell-sequencing-processes-and-studies",
    "title": "Direct Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing",
    "section": "Cell Sequencing Processes and Studies",
    "text": "Cell Sequencing Processes and Studies\nFor decades on end, cell biologists have devised multiple cell sequencing methods to navigate beyond the technical difficulties of cell examination. Scientific insight into cell cultures and tissues are basically important in cancer studies and cell other forms of cellular anomalies5.\nSingle cell sequencing (SCS) techniques have long been considered a standard procedure in inter-cellular probing. When coupled with technological advancements in genome amplification and single cell isolation, SCS produces a valuable set in cellular studies of inherent properties at high resolution.\nCurrently, leading research centers worldwide employs Single-cell whole-genome sequencing as a routine procedure in probing intercellular genomic variations and studying single-nucleotide variations in single cells.\nDespite the innovative results produced by these methods, studying genomic variations in with precise accuracy was still a big challenge in human medicine and cell biology. Scientists are consistently burdened with many question. The chief of which is – how exactly should we qualitatively study genomic features and cell heterogeneity?"
  },
  {
    "objectID": "blogs/2023-9-18-direct-library-preparation/index.html#popular-methods-of-isolating-single-cells",
    "href": "blogs/2023-9-18-direct-library-preparation/index.html#popular-methods-of-isolating-single-cells",
    "title": "Direct Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing",
    "section": "Popular Methods of Isolating Single Cells",
    "text": "Popular Methods of Isolating Single Cells\nThe scientific race to isolate single cell from a whole genome started properly in 20097. Based on available evidence and the increasing need for cell-based studies in microbiology, scientists were able to analyze transcriptome complexity in individual cells using the first cell whole transcriptome sequencing protocol.\nThe scientific race to isolate single cell from a whole genome started properly in 2009. Based on available evidence and the increasing need for cell-based studies in microbiology, scientists were able to analyze transcriptome complexity in individual cells using the first cell whole transcriptome sequencing protocol.\nTwo years later, the science evolved and single-cell whole-genome sequencing was created . This breakthrough ushered in a new wave of scientific inquiries that led to the development of a single cell whole exome sequencing in 2012, and in 2013, a novel method of single cell epigenomic sequencing was developed.\nAs expected, the methods to isolating single cell from a whole genome were formed around these protocols. Currently, there are a few methods employed by different leading research institutions around the world in isolating single cells from cell culture or tissue mass. These methods, although effective to an extent, were with many shortcomings.\nTo a large extent, the general challenge associated with these old methods is in adequately controlling the quality and quantity of cell isolates extracted from tissues or cell cultures. These old methods include: \n\nFluorescence Activated Cell Sorting (FACS)\nMicrofluidics\nMechanical Micromanipulation\n\n\n\n1. Fluorescence Activated Cell Sorting (FACS)\n\nWith wide application in microbiology, immunology, and embryonic development, Fluorescence Activated Cell Sorting is widely used in many laboratories and genomic research facilities. A popular high point linked with FACS is the ease and efficiency with which this method can isolate multiple cells (hundreds of thousands of cells) in split timing.\n\n\n\n\nFACS\n\n\n\nThe protocol of operation of cell isolation in FACS is centered on\n\nCell size\nCell Fluorescence Properties\nCell Granularity\n\nThis method is generally considered efficient and fast as it creates a unique system of cell sorting. When in use, FACS can easily isolate designated cells from a tissue sample or genome by exploring the ability of these cells to fluorescence when pre-labeled.\nThis unique property of the FACS cell-sorting protocol explains its popularity in the study f single viral particles in a poll or assemblage of mixed viral genome. When compared with recently developed protocols, such as the Direct Library Preparation Plus, the Fluorescence Activated Cell Sorting method is limited in application.\nIn this method, it is compulsory that a bulk of the cell assemblage be prepared as sorting material and samples must be prepared in solution. Earlier observation reports also holds that the fluorescent dye used in cell labeling can damage the viability of cells or influence the inherent properties of the single cells1.\n\n\n2. Microfluids\nThe shortcomings with FACS, especially the need for an abundant cell assemblage and risk of losing cell viability, led to the development of Microfluidics. This method employs a protocol setting completely different in mechanism to the FACS.\nMicrofluidics is widely used in\n\nMicrobiology\nEmbryonic development studies\nNeurobiology\n\nBasically, the Microfluidics setup7 uses a highly integrated system to achieve single cell culture and sequencing by manipulating small volumes of a few hundreds of micro-liters of fluids. As the nomenclature suggests, Microfluidics needs only a few volume of fluids in cell-based studies3.\n\n\n\n\nMicrofluidics Setup\n\n\n\nResearch institutes from around the world are currently experimenting with the feasibility of employing Microfluidics in human medicine especially in the areas of epigenomics sequencing and single cell whole-genome studies.\nIn the laboratories and microbiological studies, Microfluidics can effectively separate biological nanoparticles from tissues samples, cell cultures and cell assemblage. In a 2016 publication of Nature, the future of Microfluidics was examined based on coverage and advantage in cell sequencing6.\nReports from this review suggest that Microfluidics produces accurate results with a unique level of sensitivity in almost all research applications as reported. This method can also finely resolve nanoliter-to-picoliter volumes of samples in research studies that need timely analysis and effective outcomes in low volume fluids.\n\n\n3. Mechanical Micromanipulation\nAs an old and classic method in cell isolation and single-cell based studies, Mechanical Micromanipulation surely deserves an honorable mention. This manual method is cost-efficient and can only need cheap instrumentation especially when results are not needed to be extremely accurate.\nThis explains the continued use of Mechanical Micromanipulation in many Microbiology research laboratories around the world, despite the popularity of new methods. The Mechanical Micromanipulation setup only requires the mechanical suctioning of a single cell from a cell assemblage using a capillary pipette, microscope and other supporting instruments2.\n\n\n\n\nMechanical Manipulation setup\n\n\n\nCell isolation is not automatic and as such requires personnel guidance in the visual inspection of single-cell color features and morphological characteristics. The shortcoming of Mechanical Micromanipulation is centered on its manual processes.\nRanging from personnel faults, to mechanical shearing during manipulation and the possibility of cell damage, the shortcoming of Mechanical Micromanipulation appears to be unlimited in perspective.\nAlthough, the microscope provides a means of exact cell identification in a tissue sample, an unskilled personnel might misidentify the target cell and the whole process is time-consuming. These shortcoming are solved in Microfluidics and the Fluorescence Activated Cell Sorting method"
  },
  {
    "objectID": "blogs/2023-9-18-direct-library-preparation/index.html#direct-library-preparation-method-the-latest-innovation-in-cell-sequencing",
    "href": "blogs/2023-9-18-direct-library-preparation/index.html#direct-library-preparation-method-the-latest-innovation-in-cell-sequencing",
    "title": "Direct Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing",
    "section": "Direct Library Preparation Method: The Latest Innovation in Cell Sequencing",
    "text": "Direct Library Preparation Method: The Latest Innovation in Cell Sequencing\nThe Direct Library Preparation method of cell sequencing was developed as a scalable single-cell whole-genome sequencing platform. Compared to other methods before this innovation, the Direct Library Preparation instrumentation is perfectly designed for accuracy, high resolution and unparalleled efficiency in cell isolation experiments and research findings.\nRecently published biotech reviews on this subject matter have positioned DLP as more than just an innovation in cell isolation studies. By large, it ushers in an era where microbiology and human medicine can optimally benefit from technology.\n\n\n\n\nDLP\n\n\n\nThe instrumentation boasts of open source computational methods, image-based object recognition and commodity instrument. This innovation is widely used in many research finding for the identification of clonal populations and their corresponding genomic features.\nDirect Library Preparation has shown useful prospects in\n\nTumor studies\nMicrobiology\nNeurology\nImmunology\nEmbryonic development studies\n\nBy extension, there are theoretical evidences supporting the use of this novel method in genome heterogeneity studies, mutational processes and findings on clonal evolution in healthy and cancer tissues. Early reviews and studies on the Direct Library Preparation platform showed that it can capture a high-resolution microscopy images of cells. These images are captured as the cells navigates a transparent nozzle as they settle in wells.\nImage output allows for exact cell identification and separation. All single cell captures are lysed processes to produce unique sequencing inserts. Standard illumina protocols and allows the researcher to pool and sequence indexed libraries at the desired coverage depth.\nThe wide application of Direct Library Preparation in the research might also be linked with the innovative advantage of the development and inclusion of an open-source, cloud compatible software infrastructure. This inclusion allows the bulk storage of data and metadata produced in all sequencing and imaging processes. Based on a researcher’s preference, the result generated from this storage can be loaded into selected data visualization and assessment platform for further studies, data exploration and quality control.\nAn early report on the application of Direct Library Preparation was published by a January 2020 issue of Nature Methods. The authors in this study use Direct Library Preparation to generate a resource of 51,926 single-cell genomes and matched cell images from diverse cell types including cell lines, xenograft and diagnostic samples with limited material. The resource bulk generated allows the study of variations in mitotic mis-segregation rates across tissues types and genotypes. As expected, the analysis of genomic matches obtained and images captured aided in establishing a correlation between cellular morphology and genome ploidy states4.\nThis single review on DLP argued a case for its integration into medical sciences especially in tumor and embryonic development studies. This study, as reported, also documented the calculation of single-nucleotide resolution clonal genotypes and inferences of clonal phylogenies using aggregation of cells sharing copy number profiles. As a last result in this study, the authors also reported clone-specific chromosomal aneuploidy in polyclonal populations as defined by joint analysis of the listed features. Speculations on the readiness of DLP’s use in human medicine are currently on debate.\nHowever, there are enough evidence to argue for its usefulness in tumor studies. By allowing the measurement of clonal replication states and rare aneuploidy patterns of single cells, DLP is evidently suitable for embryonic development and tumor tracking studies.\n\nComparison, Benefits and Features\nMicrofluidics, Mechanical Micromanipulation and Fluorescence Activated Cell Sorting are methods developed early in cell isolation and single cell studies. However, the shortcoming of these methods have called for their replacement in many research studies and laboratory institutes.\nThe biggest challenge posed by these methods is that samples must be prepared in suspension and thus, the spatial location of the target cells in the tissues or cell cultures can be lost easily. Surprisingly, the Direct Library Preparation protocol is affordable and can be widely used on scalable methods in human and cellular studies.\nThis method is also widely considered a low bias method that can allow the spontaneous and in-depth analysis of variety of samples. In essence, this method can be effectively employed in genomic matching of tissues, cell assemblage and cell cultures.\n\n\nHow Direct Library Preparation Solves the Problems in Cell Sequencing\nUnlike other methods, the Direct Library Preparation method also allows the determination of copy number variations (CNV), single nucleotide polymorphisms (SNPs), phylogenic reconstructions and cluster analyses.\nThe arrays of benefits of using the DLP in research and experimental findings are limitless and include:\n\nLow reagent cost\nHigh quality of singe cell whole genome libraries\nLineage reconstructions\nUse in the analysis of any cell and nuclei from 5 to 80 micrometer.\n\nTo a large extent, DLP solved the myriads of shortcomings associated with the early methods employed in cell sequencing researches. Using the Direct Library Preparation (DLP) method in single-cell whole-genome sequencing of clinical sample is currently considered one of the best approach for cell isolation in modern biotechnology.\nThis is coming at a time when Direct Library Preparation in human medicine is increasingly becoming a topic of global scientific interest8. With time, more adoption of Direct Library Preparation method is expected to be recorded in many research facilities around the world."
  },
  {
    "objectID": "blogs/index.html",
    "href": "blogs/index.html",
    "title": "'Kolade Gracious",
    "section": "",
    "text": "While Navigating…..\n\n\n\n\nAll medical commentaries and correspondences are published in Rmarkdown/Quarto with version control on Github\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nBreathalyzers in Clinical Alcohol and Drug Care Programs\n\n\nleveraging advancements in digital technology to drive the campaign against irresponsible use of alcohol products.\n\n\n\n\nTherapy\n\n\nAlcohol\n\n\nAddiction Care\n\n\nBreathalyzers\n\n\n \n\n\n\n\nOct 9, 2023\n\n\n’Kolade Gracious\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\nDirect Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing\n\n\nExploring a novel innovation in genome sequencing\n\n\n\n\nCell\n\n\nSequencing\n\n\nBiotechnology\n\n\n \n\n\n\n\nSep 18, 2023\n\n\n’Kolade Gracious\n\n\n10 min\n\n\n\n\n\n\n  \n\n\n\n\nHOBRASIO: A Novel Therapy Regimen for Early Stage Androgenic Hair Loss\n\n\nEvaluating a multi-component integrative therapy for Alopecia forms\n\n\n\n\nTherapy\n\n\nAlopecia\n\n\n \n\n\n\n\nOct 1, 2023\n\n\n’Kolade Gracious\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\nMaintaining Standards of Care in Thoracic Surgery During the Covid-19 Pandemic in London: A Multi-site Report\n\n\nEvauating care outcomes following thoracic surgery practice during the COVID-19 pandemic\n\n\n\n\nCase Study\n\n\nCOVID-19\n\n\nReport\n\n\n \n\n\n\n\nSep 10, 2023\n\n\n’Kolade Gracious\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\nPlant-Based Dietary Approach in the Management of Third Stage Chronic Kidney Diseases\n\n\nThis clinical case study outlines the plant-based therapy plan for a 55-year-old man with a clinical diagnosis of Chronic Kidney Disease\n\n\n\n\nCase Study\n\n\nChronic Kidney Disease\n\n\nTherapy\n\n\n \n\n\n\n\nJul 21, 2023\n\n\n’Kolade Gracious\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nSulbutiamine - A Drug Review\n\n\nDeveloped as a compound that can easily increase and sustain the level of brain thiamine levels, Sulbutiamine was once a wonder drug.\n\n\n\n\nDrug Review\n\n\nPharma\n\n\nSulbutiamine\n\n\n \n\n\n\n\nSep 11, 2023\n\n\n’Kolade Gracious\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\nTechnology-based Intervention in Clinical Alcohol and Drug Addiction Care Programs\n\n\nManagement options leveraging psychosocial theories and behavioral observations developed and used as proposed models and different randomized trials for addiction care\n\n\n\n\nPharma\n\n\nAddiction\n\n\nAlcohol\n\n\n \n\n\n\n\nSep 7, 2023\n\n\n’Kolade Gracious\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\nThe Ultimate Comprehensive Guide for CBD Hemp Flower\n\n\nHemp - an industrial variation of cannabis sativa containing less than .3% THC, is the only legal source of cannabidiol. Understanding the plant atributes is considered important in the global cannabis market today\n\n\n\n\nCBD\n\n\nHemp\n\n\nCannabidiol\n\n\n \n\n\n\n\nAug 1, 2023\n\n\n’Kolade Gracious\n\n\n11 min\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "copies/index.html",
    "href": "copies/index.html",
    "title": "Copies",
    "section": "",
    "text": "Political Methodology\n\n\n \n\n\n\n\nJul 1, 2023\n\n\nGtyr Baissa, Locke Rainey\n\n\ngap\n\n\n2023\n\n\n../copies/gapweb/letter.pdf\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "copies/index.html#gap-analysis",
    "href": "copies/index.html#gap-analysis",
    "title": "Copies",
    "section": "",
    "text": "Political Methodology\n\n\n \n\n\n\n\nJul 1, 2023\n\n\nGtyr Baissa, Locke Rainey\n\n\ngap\n\n\n2023\n\n\n../copies/gapweb/letter.pdf\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "copies/index.html#website-copies",
    "href": "copies/index.html#website-copies",
    "title": "Copies",
    "section": "Website Copies",
    "text": "Website Copies\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data/index.html#sql-postgresql",
    "href": "data/index.html#sql-postgresql",
    "title": "'Kolade Gracious",
    "section": "SQL (PostgreSQL)",
    "text": "SQL (PostgreSQL)\n\n\n\n\n    \n      Errors and the Linear Model \n      \n      \n      \n        \n          Jul 1, 2023. 'Kolade Gracious.\n        \n      \n      \n         \n           GitHub Code \n        \n      \n      \n      \n    \n\n\nNo matching items"
  },
  {
    "objectID": "data/index.html#microsoft-excel",
    "href": "data/index.html#microsoft-excel",
    "title": "'Kolade Gracious",
    "section": "Microsoft Excel",
    "text": "Microsoft Excel\n\n\n\n\n    \n      When Modelling is Here \n      \n      \n      \n        \n          Jul 1, 2022. 'Kolade Gracious.\n        \n      \n      \n         \n           GitHub Code \n        \n      \n      \n      \n    \n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "’Kolade Gracious",
    "section": "",
    "text": "email\n  \n  \n    \n     Resume [Med.Writer]\n  \n  \n    \n     Resume [Data Analyst]\n  \n  \n    \n     Linkedin\n  \n\n  \n  \nSince completing my first degree in the Pharmaceutical Sciences, I have expanded my reach beyond primary healthcare by learning technical skills exploring the intersection of finance, healthcare and data science.\nCurrently, I develop medical communication solutions in pharma, medicine and professional learning with deliverables designed as continuing education courses, website copies and patients education pamphlets.\nWhen I am not writing healthcare contents, you’d find me on RStudio, Microsoft Excel or pgAdmin writing code required for exploratory data analysis, inferential statistics, and data modelling in R, SQL and DAX.\nOther times, you will probably find me somewhere in Lagos, Nigeria, discussing politics or listening to a weird mashed-up playlist of Billie Eilish, Jacob Banks, Lana Del Rey, Burna Boy, and the Nigerian sonic-artistry maestro, Brymo Olooforo.\nOh, I almost forgot! I am a big fan of film scores composed by Hans Zimmer and Ramin Djawadi.\n\nConnect\nGot writing gigs or project collaborations for me? Sounds right! Send me a brief and let’s create magic.\n\n  \n      Send Me a Brief!\n  \n\n\nYou can find me on Twitter, Linkedin and Coursera. I publicly version-control many of my data analysis and medical writing projects on GitHub. The code for this Quarto Website is Open Source can be found in a Github repo.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "journals/index.html",
    "href": "journals/index.html",
    "title": "Jounals",
    "section": "",
    "text": "No matching items\n\n Back to top"
  },
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Talks",
    "section": "",
    "text": "No matching items\n\n\nDocumenting technical e-books and continuing education courses in healthcare\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blogs/2023-09-29-hobrasio/index.html#references",
    "href": "blogs/2023-09-29-hobrasio/index.html#references",
    "title": "HOBRASIO: A Novel Therapy Regimen for Early Stage Andrigenic Hair Loss",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "blogs/2023-09-29-hobrasio/index.html#hair-loss-in-a-lifecycle-23",
    "href": "blogs/2023-09-29-hobrasio/index.html#hair-loss-in-a-lifecycle-23",
    "title": "HOBRASIO: A Novel Therapy Regimen for Early Stage Andrigenic Hair Loss",
    "section": "",
    "text": "At some points in their lifecycle, humans experience a distressing pattern of hair loss that is linked to multiple causes. Clinically, this condition is reviewed, diagnosed, and treated as ‘Alopecia.’ In many regions of the globe, alopecia is a common primary health complaint, constituting a huge portion of telemedicine services and point-of-care therapies. The pattern of hair loss in the population depends on different variables including genetic pool, healthcare efficiency index, common comorbidities, and multiple environmental triggers. The psychosocial complications arising from this condition makes prompt diagnosis and management important determinant of prognosis.\n\n\n\nAlopecia Areata\n\nThis non-scaring form of hair loss is commonly described as Circular Hair Loss. Although it rarely occurs in clustered populations, it is considered the second most popular form of alopecia. Approximately, the lifetime prevalence of alopecia areata is pegged at 2% with an almost equal incidence on both men and women. Diagnosis for this form of alopecia is common before age 30.\n\n\n\n\n\n\nNote\n\n\n\nResearch studies have confirmed multiple etiologies for alopecia areata, with the most published studies concluding on the possibility of a hereditary component. People most commonly diagnosed with alopecia areata were likely to have a few comorbidities including thyroidal dysfunctions, autoimmune conditions, atopy, and vitiligo.\n\n\nAlopecia areata presents as smooth, round patches with complete loss of hair and a retained follicular opening on the scalp and beard regions. Right on the edges of the affected region, short fragmented hair with thin shafts develops in isolated forms. Therapy delay may trigger a quick transition to ‘alopecia totalis’ –complete scalp balding or ‘alopecia universalis’ –hair loss on the body surface. The commonly adopted therapy protocols for alopecia areata involve a holistic modulation of the identified triggered for hair loss. Minoxidil, UVA therapy, and the experimental use of immunosuppressive drugs are common management options.\n\nAndrogenic Alopecia\n\nAlso described as ‘Patterned Hair Loss’, androgenic hair loss is considered the most commonly reported form of alopecia in both men and women. Data review from early studies published by the Southern Medical Journal and Dermatologic Surgery suggests that about half of androgenic alopecia male patients were diagnosed by age 50. Whereas, about 40% of androgenic alopecia female patients were diagnosed by age 70. In men, it is presented as a receding frontline with biphasic hair loss and shaft thinning. The presentation in women is slightly different with shaft thinning observed only at the crown as the anterior hairline remains preserved. In many diagnosed cases, symptoms first occur at puberty ad progress slowly until the hair loss pattern becomes noticeable.\nA diagnosis for androgenic alopecia includes a review of clinical history, family history, and pattern of symptom presentation. Many times, androgenic alopecia transitions into complete baldness in men, however, this transition is rare in female patients. Adopted therapy protocols for this condition include the recent, FDA-approved medication, Minoxidil, commercially retailed as Rogaine. Other medications including Finasteride are considered as off-label therapy options for androgenic alopecia.\n\nDiffuse Alopecia Forms\n\nUnlike the forms of alopecia mentioned already, this group of alopecia forms affects the scalp uniformly. In acute telogen effluvium, hair loss can persist for about 6 months, with shedding triggers expressed 2-4 months earlier. Diffuse alopecia forms are of multiple etiologies. The most common etiologies linked with conformed cases of this condition include endocrine diseases, thyroidal dysfunctions, malnutrition, malignancies, and stress. Once the trigger pattern is initiated, about 20-50% of the scalp hairs are induced to progress through the telogen phase until they are completely lost.\n\n\n\n\n\n\nEpidemiological Data\n\n\n\nNormally, only about 5 - 10% of hairs enter the telogen phase. The increased transition to the telogen phase experienced by telogen effluvium patients can cause complete balding.\n\n\nIn anagen effluvium, hair shedding is replaced with hair breakage. The cortex cells of the hair follicles and other epidermal structures with a high mitotic division rate are most susceptible to this breakage effect. Radiation therapy and chemotherapy are widely studies causes of this formed of diffused hair loss. Within 4 weeks, hair loss becomes noticeable with over 80% of the scalp hair is already affected. Termination of the trigger factor has shown a noticeable reduction in hair breakage. Minoxidil remains the most promising therapy option for anagen effluvium."
  },
  {
    "objectID": "blogs/2023-09-29-hobrasio/index.html#hair-loss-in-a-lifecycle-24",
    "href": "blogs/2023-09-29-hobrasio/index.html#hair-loss-in-a-lifecycle-24",
    "title": "HOBRASIO: A Novel Therapy Regimen for Early Stage Andrigenic Hair Loss",
    "section": "",
    "text": "At some points in their lifecycle, humans experience a distressing pattern of hair loss that is linked to multiple causes. Clinically, this condition is reviewed, diagnosed, and treated as ‘Alopecia.’ In many regions of the globe, alopecia is a common primary health complaint, constituting a huge portion of telemedicine services and point-of-care therapies. The pattern of hair loss in the population depends on different variables including genetic pool, healthcare efficiency index, common comorbidities, and multiple environmental triggers (Goldberg 2023). The psychosocial complications arising from this condition makes prompt diagnosis and management important determinant of prognosis.\n\n\n\nAlopecia Areata\n\nThis non-scaring form of hair loss is commonly described as Circular Hair Loss. Although it rarely occurs in clustered populations, it is considered the second most popular form of alopecia. Approximately, the lifetime prevalence of alopecia areata is pegged at 2% with an almost equal incidence on both men and women. Diagnosis for this form of alopecia is common before age 30.\n\n\n\n\n\n\nNote\n\n\n\nResearch studies have confirmed multiple etiologies for alopecia areata, with the most published studies concluding on the possibility of a hereditary component. People most commonly diagnosed with alopecia areata were likely to have a few comorbidities including thyroidal dysfunctions, autoimmune conditions, atopy, and vitiligo (Mysore, Chandrashekar, and Yepuri 2014).\n\n\nAlopecia areata presents as smooth, round patches with complete loss of hair and a retained follicular opening on the scalp and beard regions. Right on the edges of the affected region, short fragmented hair with thin shafts develops in isolated forms. Therapy delay may trigger a quick transition to ‘alopecia totalis’ –complete scalp balding or ‘alopecia universalis’ –hair loss on the body surface. The commonly adopted therapy protocols for alopecia areata involve a holistic modulation of the identified triggered for hair loss. Minoxidil, UVA therapy, and the experimental use of immunosuppressive drugs are common management options.\n\nAndrogenic Alopecia\n\nAlso described as ‘Patterned Hair Loss’, androgenic hair loss is considered the most commonly reported form of alopecia in both men and women. Data review from early studies published by the Southern Medical Journal and Dermatologic Surgery suggests that about half of androgenic alopecia male patients were diagnosed by age 50. Whereas, about 40% of androgenic alopecia female patients were diagnosed by age 70. In men, it is presented as a receding frontline with biphasic hair loss and shaft thinning. The presentation in women is slightly different with shaft thinning observed only at the crown as the anterior hairline remains preserved [(Qi and Garza 2014; Strazzulla et al. 2018)]. In many diagnosed cases, symptoms first occur at puberty ad progress slowly until the hair loss pattern becomes noticeable.\nA diagnosis for androgenic alopecia includes a review of clinical history, family history, and pattern of symptom presentation. Many times, androgenic alopecia transitions into complete baldness in men, however, this transition is rare in female patients. Adopted therapy protocols for this condition include the recent, FDA-approved medication, Minoxidil, commercially retailed as Rogaine. Other medications including Finasteride are considered as off-label therapy options for androgenic alopecia.\n\nDiffuse Alopecia Forms\n\nUnlike the forms of alopecia mentioned already, this group of alopecia forms affects the scalp uniformly. In acute telogen effluvium, hair loss can persist for about 6 months, with shedding triggers expressed 2-4 months earlier. Diffuse alopecia forms are of multiple etiologies. The most common etiologies linked with conformed cases of this condition include endocrine diseases, thyroidal dysfunctions, malnutrition, malignancies, and stress. Once the trigger pattern is initiated, about 20-50% of the scalp hairs are induced to progress through the telogen phase until they are completely lost.\n\n\n\n\n\n\nEpidemiological Data\n\n\n\nNormally, only about 5 - 10% of hairs enter the telogen phase. The increased transition to the telogen phase experienced by telogen effluvium patients can cause complete balding.\n\n\nIn anagen effluvium, hair shedding is replaced with hair breakage. The cortex cells of the hair follicles and other epidermal structures with a high mitotic division rate are most susceptible to this breakage effect. Radiation therapy and chemotherapy are widely studies causes of this formed of diffused hair loss. Within 4 weeks, hair loss becomes noticeable with over 80% of the scalp hair is already affected. Termination of the trigger factor has shown a noticeable reduction in hair breakage. Minoxidil remains the most promising therapy option for anagen effluvium."
  },
  {
    "objectID": "blogs/2023-09-21-tuberculosis/index.html",
    "href": "blogs/2023-09-21-tuberculosis/index.html",
    "title": "Epidemiology of Tuberculosis: A Case Study (2000 - 2016)",
    "section": "",
    "text": "Tuberculosis is linked with about 40% of deaths occurring in the global population of people living with human immunodeficiency virus2. In the global population, is generally considered as the leading cause of death (WHO, 2018) in single disease infections. Tuberculosis has a dated history with the human race. Scientific evidence supporting survival through time has been validated by recent findings indicating that the causative organism no known environmental reservoir. This infection caused by Mycobacterium tuberculosis is known to mainly affect the lungs, presenting in humans as the most common pulmonary disease4.\nThe primary route of transmission between humans has long been established as airborne. Depending on the environmental conditions at exposure and the severity of infection of the source patient, tuberculosis can present differently. At the initial stage of infection (Primary TB), the symptoms resolve rapidly in many healthy individuals. In immuno-compromised persons, the infection progresses to a secondary stage and require therapy. Latent tuberculosis is diagnosed in persons with a dormant Mycobacterium tuberculosis variant.\n\n\n\n\n\n\nNote\n\n\n\nThis paper examines the epidemiology of Tuberculosis over a 16-year period from 2000 to the initiation of the End TB Strategy in 2016.\n\n\n\n\nIn 2016, an estimate of 10.4 million new cases were reported globally. An estimated 10% of this total number were recorded in immuno-compromised patients (HIV-positive). The numbers recorded this year follows a trend of decline that have been recorded since year 2000 (1.4% decline per year). The mortality rate linked to TB has also been on a steady decline since year 2000, with 1.7 million in 2000 to 1.3 million in 2016 among the HIV-positive population. Between 2015 – 2016, the mortality rate (measures as deaths per 100,000 people annually) among the HIV-negative population decreased by 3.4%.\n\n\n\n\nProjection for the incidence and mortality of Tuberculosis as set by the End TB Strategy (2016 - 2035) (WHO, 2017)\n\n\n\n\n\n\nGlobal estimate on the incidence and mortality rate of Tuberculosis, 2000-2016 (WHO, 2017)\n\n\n\n\n\nA decline in the rate of TB incidence and mortality were noticed in countries implementing the End TB strategy, especially in Europe. In heavy burden countries in Africa including Zambia, Lesotho, Kenya, Namibia and Zimbabwe, the rate of decline in cases recorded was estimated as 4% annually from 2015. As at 2016, the regional incidence of Tuberculosis varied by geographical locations and degree of strategy implementation.\nSeven countries contribute an estimated 64% to the global incidence rate. India recorded 27% of the global incidence cases (measured as new cases per 100,000 people annually), Indonesia recorded 10%, China, 9%, Philippines 5% Pakistan, 5%, South Africa, 4% and Nigeria, 4%. Countries in the European region accounted for 3% of the global incidence and the Eastern Mediterranean region contributed 7%.\n\n\n\n\n(A) Number of cases recorded for countries with over 100,000 cases (WHO, 2017) (B) Annual tuberculosis incidence (per 100,000 population), by region — worldwide, 2016\n\n\n\n\n\n\nTuberculosis incidence and mortality were mostly studied in the general population as divide between immuno-compromised persons and healthy persons. However, in the Global Tuberculosis Report published by WHO in 2017, the incidence cases by sex was analyzed. For both sexes, incidence of tuberculosis was highest in the population of people between 25-34 years. Incidence was lowest in children below 4 years and children within the 5 -14-year age bracket."
  },
  {
    "objectID": "blogs/2023-09-21-tuberculosis/index.html#overview",
    "href": "blogs/2023-09-21-tuberculosis/index.html#overview",
    "title": "Epidemiology of Tuberculosis: A Case Study (2000 - 2016)",
    "section": "",
    "text": "Tuberculosis is linked with about 40% of deaths occurring in the global population of people living with human immunodeficiency virus2. In the global population, is generally considered as the leading cause of death (WHO, 2018) in single disease infections. Tuberculosis has a dated history with the human race. Scientific evidence supporting survival through time has been validated by recent findings indicating that the causative organism no known environmental reservoir. This infection caused by Mycobacterium tuberculosis is known to mainly affect the lungs, presenting in humans as the most common pulmonary disease4.\nThe primary route of transmission between humans has long been established as airborne. Depending on the environmental conditions at exposure and the severity of infection of the source patient, tuberculosis can present differently. At the initial stage of infection (Primary TB), the symptoms resolve rapidly in many healthy individuals. In immuno-compromised persons, the infection progresses to a secondary stage and require therapy. Latent tuberculosis is diagnosed in persons with a dormant Mycobacterium tuberculosis variant.\n\n\n\n\n\n\nNote\n\n\n\nThis paper examines the epidemiology of Tuberculosis over a 16-year period from 2000 to the initiation of the End TB Strategy in 2016.\n\n\n\n\nIn 2016, an estimate of 10.4 million new cases were reported globally. An estimated 10% of this total number were recorded in immuno-compromised patients (HIV-positive). The numbers recorded this year follows a trend of decline that have been recorded since year 2000 (1.4% decline per year). The mortality rate linked to TB has also been on a steady decline since year 2000, with 1.7 million in 2000 to 1.3 million in 2016 among the HIV-positive population. Between 2015 – 2016, the mortality rate (measures as deaths per 100,000 people annually) among the HIV-negative population decreased by 3.4%.\n\n\n\n\nProjection for the incidence and mortality of Tuberculosis as set by the End TB Strategy (2016 - 2035) (WHO, 2017)\n\n\n\n\n\n\nGlobal estimate on the incidence and mortality rate of Tuberculosis, 2000-2016 (WHO, 2017)\n\n\n\n\n\nA decline in the rate of TB incidence and mortality were noticed in countries implementing the End TB strategy, especially in Europe. In heavy burden countries in Africa including Zambia, Lesotho, Kenya, Namibia and Zimbabwe, the rate of decline in cases recorded was estimated as 4% annually from 2015. As at 2016, the regional incidence of Tuberculosis varied by geographical locations and degree of strategy implementation.\nSeven countries contribute an estimated 64% to the global incidence rate. India recorded 27% of the global incidence cases (measured as new cases per 100,000 people annually), Indonesia recorded 10%, China, 9%, Philippines 5% Pakistan, 5%, South Africa, 4% and Nigeria, 4%. Countries in the European region accounted for 3% of the global incidence and the Eastern Mediterranean region contributed 7%.\n\n\n\n\n(A) Number of cases recorded for countries with over 100,000 cases (WHO, 2017) (B) Annual tuberculosis incidence (per 100,000 population), by region — worldwide, 2016\n\n\n\n\n\n\nTuberculosis incidence and mortality were mostly studied in the general population as divide between immuno-compromised persons and healthy persons. However, in the Global Tuberculosis Report published by WHO in 2017, the incidence cases by sex was analyzed. For both sexes, incidence of tuberculosis was highest in the population of people between 25-34 years. Incidence was lowest in children below 4 years and children within the 5 -14-year age bracket."
  },
  {
    "objectID": "blogs/2023-09-21-tuberculosis/index.html#discussing-available-data-trends",
    "href": "blogs/2023-09-21-tuberculosis/index.html#discussing-available-data-trends",
    "title": "Epidemiology of Tuberculosis: A Case Study (2000 - 2016)",
    "section": "Discussing Available Data Trends",
    "text": "Discussing Available Data Trends\nThe mortality rate of tuberculosis in healthy and immuno-compromised persons have triggered a global response to stem the tide of infection. In 2017, over 10 million incident cases of tuberculosis was recorded, with mortality set at 1.57 million deaths (WHO, 2018). The stats recorded showed a steadily decline in the global Tuberculosis burden as recorded in the previous year –about 1.8% decline in incident cases and 3.9% decline in global deaths due to tuberculosis.\n\n\n\n\n\n\nAbout DOTS\n\n\n\nThe World Health Organization introduce the DOTS strategy in 2000, until it was replaced by the Stop TB strategy in 2006.\n\n\nBoth strategies were aimed at halting and reversing tuberculosis incidence and reducing the tuberculosis prevalence and mortality by 50% by 2015. In 2016, the World Health Organization commenced a post-2015 tuberculosis strategy (End TB Strategy) aimed at ending the global tuberculosis epidemic. This new strategy was expected to cover the 2016 – 2035 TB analysis period, achieving a 35% reduction in absolute number of TB deaths and a 20% reduction in TB incidence by 2020.\n\nAs it stands, the rate of decline in incidence and death will not be enough to meet the WHO End TB strategy target for 2035. Substantial reduction in tuberculosis deaths will be necessary to meet the first installment aim by 2030.\n\nVariations in the epidemiology of TB have been consistently tracked by geographical distribution and, now by sex and age distribution. Africa constitutes one of the highest regional prevalence rate of tuberculosis. Co-infection with HIV is considered an important factor in the rate of TB epidemic in this region.\n\n\n\n\n\n\nNote\n\n\n\nA compromised immune system has been linked with increased mortality in people infected with mycobacterium tuberculosis1\n\n\nIn Asia, the data recorded by the WHO datasheet on global Tuberculosis burden show similarity to that in Africa. The incidence rate revealed a rising case of tuberculosis infection in the region. However, compared to Africa, there is a lower burden of HIV infection in this region. Other risk factors such as poverty, undernutrition, poor hygiene control in crowded spaces and lack of adequate medical care contributes to the driving force of tuberculosis infection in this region.\nIn Europe, the cluster of countries only contributes about 3% to the global incidence of tuberculosis in 2016. The burden of tuberculosis in this region tilts toward therapy failure and not risk factors that substantially increases new infections as in Africa and Asia. Multi-drug resistant TB strains (MDR TB) is considered a major problem in Europe. The proportion of MDR TB cases in this region is about 5 times higher compared with other regions, posing a major challenge in treating cases of tuberculosis. Enhanced strategies might be needed to combat the prevalence of TB in this region. Experts have suggested pre-testing and treatment for multi-drug resistant TB, screening for coinfection with HIV among the vulnerable groups and addressed the challenges posed by poverty and malnutrition.\nReviews on the global burden of tuberculosis opened new insights into how to better control annual incidence rate of tuberculosis in a bid to meet the target for 2035. As at 2016, an estimated one third of the global population has latent TB infection and are at direct risk for a secondary infection that can significantly increases future risk for TB3.\n\n\n\n\n\n\nNote\n\n\n\nIn 2018, the WHO recognized this problem and released an updated guideline for the management of Latent TB.\n\n\nThis therapy guideline was slowly implemented in many countries and current data suggest that the coverage level falls below the End TB strategy target for 2025. Treatment of latent TB can directly impact the incidence and prevalence rate recorded for tuberculosis infections globally in subsequent years\nThe World Health Organization and regional health bodies continuously examine and optimized the Stop TB strategies as it applies in their regions. Many scientific reviews have called for regional annual reports on incidence and mortality to better estimate the improvement in the global TB burden. This can also help for objective assessment of the WHO data sheet on tuberculosis annually and to track improvement in epidemic control. The data sheet on Tuberculosis presented by WHO in 2016, was reportedly based on direct reflections from national surveys on tuberculosis by 24 countries. This accounts for 68% of the global burden of this infection. Standard adjustments on data allow for underreporting or under-diagnosing for 134 countries constituting 15% of the global TB burden.\nDuring the period tracked in this paper, the estimation of death caused by tuberculosis was based on national registration of cases of death for 129 countries constituting 57% of the estimated tuberculosis death globally. WHO also used estimates produced by the Institute of Health Metrics to estimate tuberculosis death in 18 countries. Currently, the epidemiologic estimates only show modest improvement in the global TB burden, as determined by steadily declining incidence, mortality and prevalence rate, pegged at an average of 1.4% annually. Intensified and concerted effort are needed to meet the targets set for 2035 and beyond.\nInnovative approaches and modification of the strategy guidelines are required in regions with a significant annual burden of tuberculosis. These include pre-screening for HIV co-infection, implementation of latent TB therapy guidelines, innovative TB therapy regimen and ensuring hygiene in clustered regions, especially in Africa and Asia. These strategies are tipped to significantly decreases the global burden of TB in subsequent years."
  },
  {
    "objectID": "blogs/2023-09-10-thoracic/index.html",
    "href": "blogs/2023-09-10-thoracic/index.html",
    "title": "Maintaining Standards of Care of Care in Thoracic Surgery During the Covid-19 Pandemic in London: A Multi-site Report",
    "section": "",
    "text": "Key Question\n\n\n\nHow does the COVID-19 pandemic affect the clinical course of disease and outcomes of surgical care in lobectomy patients?\n\n\n\n\n\n\n\n\nFinding(s)\n\n\n\nThere were no mortality cases in the study population, with only two patients transferred to another hospital for further specialized care.\n\n\n\n\n\n\n\n\nConclusive Findings\n\n\n\nBy establishing and maintaining the protocols of standard care during the COVID-19 pandemic for thoracic surgery patients, the mortality rate can be reduced to zero.\n\n\n\nMETHODS\nThis retrospective study is assessing lung resections performed during the period of March – September 2020. A thoracic surgery protocol was implemented, which included telephone/video initial consultation, pre-habilitation for high-risk patients, virtual pre-assessment followed by a day of surgery admission. Data was collected through the patient assessment and tracking system.\n\n\nRESULTS\nA total of 214 patients underwent lung resection, of which 99 patients had a lobectomy. The mean age was 64.4 (10-87), and 57 were females. The mean thoracoscope was 1.66 (0.06 – 9.5), mean length of stay was 5.5 days (1-24). There was no recorded mortality during this period. Seven patients had post-operative complications, including pneumonia, respiratory failure requiring ventilatory support in the intensive care unit, and one completion pneumonectomy. Most importantly, none of the patients developed COVID-19 infection post-operatively.\n\n\nCONCLUSION\nA total of 214 patients underwent lung resection, of which 99 patients had a lobectomy. The mean age was 64.4 (10-87), and 57 were females. The mean thoracoscope was 1.66 (0.06 – 9.5), mean length of stay was 5.5 days (1-24). There was no recorded mortality during this period. Seven patients had post-operative complications, including pneumonia, respiratory failure requiring ventilatory support in the intensive care unit, and one completion pneumonectomy. Most importantly, none of the patients developed COVID-19 infection post-operatively.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blogs/2023-09-10-thoracic/index.html#introduction",
    "href": "blogs/2023-09-10-thoracic/index.html#introduction",
    "title": "Maintaining Standards of Care in Thoracic Surgery During the Covid-19 Pandemic in London: A Multi-site Report",
    "section": "INTRODUCTION",
    "text": "INTRODUCTION\nAs of January 2021, the World Health Organization (WHO) estimated the total number of COVID-19 infection cases as over 98 million globally. Up to the date of this review, the last weekly epidemiological report declared the total number of global death rates are over 2 million since the start of the pandemic [1]. Announcing COVID-19 as a pandemic by the WHO in March 2020, the Coronavirus disease has significantly reshaped life and daily living around every corner of the world.\nIts impact on the medical practice and surgical management have been most devastating. Although the race for a treatment protocol and vaccine started earlier, healthcare providers globally felt the crushing blow of this novel viral infection. No doubt, the health dangers of delayed surgical procedures are well-defined.\nAs the reported cases of daily infection surged significantly, the need to develop and measure the variables that directly measures the impacts of COVID-19 infections on clinical procedures also developed. The data and evidence gathered from such measures were projected to guide updated reviews of medical practices as the pandemic rages on (2).\nIn health facilities with active cases of COVID-19, physicians were forced to update treatment protocols and closely monitor parameters such as drug effectiveness, surgical outcomes, and disease resolution index (3). Research teams worked in different healthcare facilities, including a COVID-19 Centre, studying the clinical outcomes of thoracic surgery in the pandemic\n\n\n\n\n\n\nImportant\n\n\n\nOur goal, with this research, is to evaluate the clinical outcomes following elective thoracic surgery –Lobectomies – in a participant pool of 93 patients during the COVID-19 pandemic in non-COVID-19 and a COVID-19 center."
  },
  {
    "objectID": "blogs/2023-09-10-thoracic/index.html#methodology",
    "href": "blogs/2023-09-10-thoracic/index.html#methodology",
    "title": "Maintaining Standards of Care in Thoracic Surgery During the Covid-19 Pandemic in London: A Multi-site Report",
    "section": "METHODOLOGY",
    "text": "METHODOLOGY\nThis retrospective study is assessing lung resections during the period of March – September 2020. A COVID-19 based thoracic surgery protocol was implemented, which included telephone/video initial consultation, pre-rehabilitation for high-risk patients, virtual pre-assessment followed by a day of surgery admission. Data was collected through the patient assessment and tracking system."
  },
  {
    "objectID": "blogs/2023-09-10-thoracic/index.html#results-1",
    "href": "blogs/2023-09-10-thoracic/index.html#results-1",
    "title": "Maintaining Standards of Care in Thoracic Surgery During the Covid-19 Pandemic in London: A Multi-site Report",
    "section": "RESULTS",
    "text": "RESULTS\nA total of 214 patients underwent lung resection, of which 99 patients had lobectomy [Table 1]. The mean age was 64.4 (10-87), and 54 were females. The mean thoracoscope was 1.66 (0.06 – 9.5), mean length of stay was 5.5 days (1-24) [Table 2].\n\nTable1: Gender distribution of lobectomy patients\n\n\nGender\nN\nMean\nMedian\nStd. Deviation\nRange\n\n\n\n\nFemale\n54\n5.11\n4.00\n4.360\n23\n\n\nMale\n39\n5.54\n5.00\n4.103\n22\n\n\nTotal\n93\n5.29\n4.00\n4.236\n23\n\n\n\nhjeyeded\n\nTable 2: Age Distribution of patients at admission\n\n\nAge at Admision\nN\nMean\nMedian\nCol5\nCol6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere was no recorded mortality during this period. Seven patients had post-operative complications, including pneumonia, respiratory failure requiring ventilatory support in the intensive care unit, and one completion pneumonectomy (Table 2-3). None of the patients developed COVID-19 infection post-operatively. \n\n\n\nFig. 1: Summary of primary post-operative complications of the study pool\n\n\nWhen compared with our pre-COVID data for the same time period in 2019, these results are comparable in terms of mortality, morbidity, and length of stay [Table 3].\n\n\n\nFig. 2: Comparing pre-COVID data for 2019 (March - September)\n\n\nWe used Pando (mobile app) and Microsoft teams to ensure closer communication between members of the multidisciplinary team.  During this time, our junior staff was co-opted to work on intensive care, while we were also providing thoracic support to the ECMO and ITU teams, and we were also sharing theatre lists with other units from across London. \n\n\n\nFig. 3: Comparing discharge destination with a mean length of post-surgical stay\n\n\n\n\n\nFig. 4: Smoking history distribution"
  },
  {
    "objectID": "blogs/2023-09-10-thoracic/index.html#discussion",
    "href": "blogs/2023-09-10-thoracic/index.html#discussion",
    "title": "Maintaining Standards of Care in Thoracic Surgery During the Covid-19 Pandemic in London: A Multi-site Report",
    "section": "DISCUSSION",
    "text": "DISCUSSION\nMany research studies have highlighted the post-operative risks and outcome impacts of COVID-19 on patients undergoing surgical procedures, , while others have directly documented the morbidity scores of delayed surgical resection (4). Ahmed et al. [5] carefully recommended the protocols for disinfection and surgical maneuvers for anesthesiologists and surgeons performing thoracic surgery on a patient. The general index for post-operative pulmonary complications is low; however, the presence of comorbidities and viral infections can affect the diagnostic workup and surgical outcome. With reference to an earlier report [6] confirming that undiagnosed cases of COVID-19 infection may complicate post-operative recovery. Ahmed et al. also defined the modalities for post-operative care and elective ICU admissions in surgical cases with a suspected or confirmed COVID-19 infection.\nAt the time of compiling these results, the team was not aware of any similar reports exactly detailing the outcome of elective lung lobectomies during the COVID-19 pandemic. This report, to the best of our knowledge, is the first of its kind globally, reconciling the parameters defining standardized patient care with the outcomes of elective surgery as affected by COVID-19 infection. Although, there are studies proposing new ideas on emergency thoracic surgery patient care irrespective of COVID-19 (7) On admission, preoperative history of comorbidities and at-risk behaviors were documented for every patient.\nAt the time of research reporting, our team was unaware of any large-scale cohort studies statistically evaluating the post-operative risks and complications of lobectomies associated with a COVID-19 infection. The only relevant studies, in this case, were published by Lei et al. [8]. Lei’s team reports statistical data on the outcomes and clinical characteristics as observed in 34 surgical cases in Wuhan City, Hubei Province, China. Three high-mortality thoracic surgery cases were captured; however, the majority of the surgical cases were on oncological surgeries with no patient confirmed of an active COVID-19 infection prior to surgery. The data from Wuhan suggested that the percentage of patients requiring post-operative critical care (44.1%) was higher than the general population of patients on admission with COVID-19-related health complications.\nLimited by lockdown protocols of the pandemic, our team decided to incorporate telemedicine into the standardized care plan drafted for these patients [9]. As a safe and modern method of remote healthcare delivery, the study population was introduced to Microsoft tams and Pando –a mobile app –for pre-and post-surgical monitoring. The procedures and schedule for communication and feedback analysis from these platforms followed early protocols in remote healthcare delivery for surgical cases. Robert et al. [10] earlier described the safety and efficiency of telemedicine in delivering preoperative and post-operative clinical care to patients scheduled for thoracic surgery.  The submissions of this early research explained how the authors confirmed that telemedicine safely determines oncologic surgical resectability and patient fitness and providing outstanding outcomes in surgical care.\nOur team is aware of an earlier study exploring the prevalence of smoking rate and comorbidities in evaluating the relationship between disease severity and mortality during the COVID-19 pandemic. Tayfun and Bengu [11] concluded in this study that smoking, cardiac disease, congestive pulmonary diseases, and old age are risk factors for intensive care admission and mortality in COVID-19 patients. The comorbidities and at-risk behaviors documented in our study pool include smoking [13 current smokers, 54 ex-smokers], renal failure [13], steroid therapy [4], and diabetes [2 diets controlled, 1 insulin-dependent, 10 oral therapy, and diet controlled].\nAlthough the lobectomies captured in this report were elective, patient care was directed at providing efficient clinical care in line with COVID-19 protocol guidance for triage of operations for thoracic malignancies [12]. It is important to emphasize the integration of telemedicine using the Pando mobile app to deliver medical care during this study. We believe that the zero morbidity rate recorded during this study is in part aided by utilizing technology in the postoperative and preoperative setting for patient evaluation and to triage any potential complications (13). The mean length of post-surgical hospital stay recorded was also compared with pre-COVID data for the same period (March – September) in 2019. We had a significant reduction in the mean length of post-surgical hospital stay, with the 2020 value pegged at 5 as against the higher 2019 value at 7.\nOf the 93 patients observed during this study, 72 developed no primary complications, with the remaining 21 patients developing various primary complications ranging from acute post-surgical troublesome pain, arrhythmia, cardiac arrest, mild gastric dilatation, persistent air leak, surgical emphysema, post-operative pneumonia, and other acute abdominal conditions requiring laparotomy. We recorded and analyzed the relationship between these complications and other variables of this study, including the mean of length of post-surgical hospital stay. The group of patients that developed other acute abdominal conditions requiring laparotomy as a primary complication stayed the longest in the hospital at a mean length of post-surgical stay of 5 days.\nPost-operative secondary complications diagnosed in the study cases were also documented.  Eighty-nine patients developed no secondary complications as supportive care for primary complications were swiftly initiated. However, one patient developed mild arrhythmia requiring no treatment other than drugs, one patient developed atelectasis (collapse), another was diagnosed with persistent air leak, and the last patient developed a case of pleural effusion of an unknown cause. We recorded no case of tertiary complications. Therapy was considered largely successful as all members of the ninety-three patient pool were discharged with no recorded of mortality.\nThe discharged destinations were different for our patients, with two patients alive and transferred to another hospital/department and ninety-one patients discharged home. None of the patients contracted the COVID-19 post-operatively and during the entire stay in the hospital. In an earlier report conducted on patients with a laboratory-confirmed COVID-19 in 552 hospitals in China, the overall incubation time was pegged at 4.0 days (interquartile range 2 – 7). Our study cases stayed for more than the confirmed incubation periods and recorded no suspicious symptoms suggestive of a COVID-19 infection. Post-operative care is expected to continue with the already established COVID-19 protocol guidance for the triage of thoracic malignancy operations (14)."
  },
  {
    "objectID": "blogs/2023-09-10-thoracic/index.html#conclusion-1",
    "href": "blogs/2023-09-10-thoracic/index.html#conclusion-1",
    "title": "Maintaining Standards of Care in Thoracic Surgery During the Covid-19 Pandemic in London: A Multi-site Report",
    "section": "CONCLUSION",
    "text": "CONCLUSION\nOur study shows that through the implementation of a COVID-19 based thoracic protocol, we were able to maintain a high standard of care during the COVID-19 pandemic with no mortality and low morbidity. We achieved this feat despite working across three different COVID-19 centers. Our junior staff was actively involved in patient care protocols as they were drafted to cover the intensive care unit at these sites. Our result findings resonate with earlier submissions on the outcomes of researches earlier conducted to evaluate the safety of patients and providers in lung cancer surgery during the COVID-19 pandemic (15). Effective communication using teams and Pando allowed us to deliver safe patient care."
  },
  {
    "objectID": "blogs/2023-09-11-sulbutiamine/index.html",
    "href": "blogs/2023-09-11-sulbutiamine/index.html",
    "title": "Sulbutiamine - A Drug Review",
    "section": "",
    "text": "Sulbutiamine is a lipid-soluble derivative of thiamine originally developed in the 60’s by Japanese scientists as an adjunctive treatment for the management of symptom spectrum linked closely with Vitamin B deficiency. Sold under the brand name ‘Arcalion’, Sulbutiamine has since been modified and explored in the management of asthenia, depression, erectile dysfunction, Alzheimer’s disease and diabetic neuropathy.\nThe rationale behind the development of Sulbutiamine is simple –a compound that can easily increase and sustain the level of brain thiamine levels was needed to reverse the symptoms of thiamine deficiency. Thiamine is polar, making it soluble in water and decreasing its rate of penetration of the blood-brain barrier. As an oxidized derivative of thiamine, Sulbutiamine is a non-polar dimer of thiamine that crosses the blood-brain barrier and metabolized to release more thiamine molecules in the brain. This profile increases the bioavailability of thiamine in the brain, decreases thiamine metabolism and combats thiamine deficiency. This is the sole basis for the cognitive-enhancing properties of Sulbutiamine."
  },
  {
    "objectID": "blogs/2023-09-11-sulbutiamine/index.html#sulbutiamine-in-clinical-care",
    "href": "blogs/2023-09-11-sulbutiamine/index.html#sulbutiamine-in-clinical-care",
    "title": "Sulbutiamine - A Drug Review",
    "section": "Sulbutiamine in Clinical Care",
    "text": "Sulbutiamine in Clinical Care\n\n1. Cognitive Enhancement\nSulbutiamine is known to give an extra kick when needed. This is the primary reason for its use among millions of people. As a synthetic derivative of thiamine, it induces a mild stimulatory effect by enhancing the actions of dopamine at the expense of other catecholamine. Sulbutiamine is preferred to amphetamines and other cognitive-enhancing therapies as it presents no significant adverse effects on the users. As a non-prescription drug, it is considered a supplement therapy in Alzheimer’s patients as it increases attention span and improves treatment indices.\n\n\n2. Long-term Memory Formation\nMany clinical evidence and research results are currently supporting the use of Sulbutiamine in the stimulation of long-term memory formation. Sulbutiamine interacts significantly with neurotransmitters directly involved in memory formation –choline, dopamine and glutamate responds readily to the modulatory effects of Sulbutiamine in humans. Investigating the role of Sulbutiamine in long-term memory formation, a research study published by the Journal of Pharmacology Biochemistry and Behavior submitted that this compound mediates an increase in hippocampal cholinergic activity by inducing an uptick in sodium dependent high affinity choline uptake1. The steps involved are beyond the scope of this review.\nSummarily, Sulbutiamine increases the rate impulse transmission in the brain receptor and improves glutamate flow in a bid to enhancing memory formation. There are also studies explaining the effectiveness of Sulbutiamine in reversing the adverse effects of amnesia-inducing drugs on memory formation.\n\n\n3. Erectile Dysfunction Suplementary Therapy\nCurrently, there are enough claims and anecdotal evidences to fuel a clinical investigation about the usefulness of Sulbutiamine in reversing erectile dysfunction. In 2005, a study published by the Russian journal, Urologiia, detailed the usefulness of Sulbutiamine in the management of psychogenic erectile dysfunction. In this study, 20 patients with confirmed cases of psychogenic erectile dysfunction received optimal does of Sulbutiamine over a course of 30 days. In some patients with preexisting arterial disorders, an improvement in cavernous arterial blood flow was recorded.\n\n\n4. Improved Mood and Reduction in Anxiety Levels\nThough not yet extensively proven by clinical research standards, there are many theories suggesting that Sulbutiamine can actively elevate mood and reduce anxiety in users. As initially discussed, Sulbutiamine significantly effects the activities of the body’s excitatory neurotransmitters especially glutamate and dopamine. In normal humans, dopamine is linked with emotional response, motivation and feelings of pleasure.\nBy increasing dopaminergic transmission, Sulbutiamine can be expected to improve mood. In the year 2000, this basis was investigated in a clinical research published by L’Encephale. The efficacy of Sulbutiamine on the symptoms of patients with Major Depressive Episode (MDE) was examined in a placebo control trial. This study confirmed that Sulbutiamine is effective in rehabilitating patients in their social and family life functioning3.\n\n\n5. Energy Boost in Chronic Fatigue\nJudging from a few clinical studies, Sulbutiamine has proven to be useful in the treatment of posttraumatic fatigue characterized by low energy levels. Since its use with anti-infective medications is not contraindicated, many physicians now explore this combination posttraumatic patients to boost mood and increase energy levels. A non-randomized observational study investigating the effect of Sulbutiamine in patients with infection associated asthenia was by published by The Journal of the Association of Physicians of India in 2003.\nAn inspection of the primary outcome data revealed that the number of patients with complete resolution of all asthenic symptoms was over 50%. In some patients, severe asthenia was significantly reduced, however, response was greater in patients with acute infection and symptom presentation4. Sulbutiamine is also effective in the management of fatigue associated with multiple sclerosis and in persistent bouts of unexplained fatigue."
  },
  {
    "objectID": "blogs/2023-09-11-sulbutiamine/index.html#sulbutiamines-pharmacology",
    "href": "blogs/2023-09-11-sulbutiamine/index.html#sulbutiamines-pharmacology",
    "title": "Sulbutiamine - A Drug Review",
    "section": "Sulbutiamine’s Pharmacology",
    "text": "Sulbutiamine’s Pharmacology\nAs an emerging drug component, different medical enquiries have been conducted to investigate the mechanism by which Sulbutiamine exerts its biochemical effects in humans. These findings revealed a multi-system mechanism amplified by Sulbutamine’s interaction with neuronal cells, biological antioxidants, neurotransmitters and different regions of the brain. In addition to increasing circulating thiamine levels, other documented mechanism of action of Sulbutiamine in human subjects include:\n\nSulbutiamine increases the activities of Dopamine and Glutamate in the prefrontal cortex region of the brain. A study published in 2000 by Neuroscience Letters concluded that Sulbutiamine exerts a modulatory effect on dopaminergic and glutaminergic cortical transmission by decreasing kainite binding sites and increasing Dopamine (D1) binding sites4.\nSulbutiamine decreases the rate of neuronal cell death (as induced by serum deprivation) by a dose-dependent stimulation of the activities of glutathione (GSH) and Glutathione-S-transferase. A research study published in the Biological and Pharmaceutical Bulletin revealed that Sulbutiamine inhibits oxidative stress by scavenging reactive oxidative species (ROS) in neuronal cells –an action that consequently reduces brain cell death4.\nIn experimental models, Sulbutiamine has been shown to increase hippocampal cholinergic activity by a direct effect on central cholinergic pathway. This mechanism is however complex and still under further scrutiny by different research groups. However, different publications have confirmed that chromic administration of Sulbutiamine directly improves the ability of experimental rats to form long term memory.\n\nSulbutiamine has also been proven to increase energy use in the brain by directly stimulating the levels of thiamine triphosphate2."
  },
  {
    "objectID": "blogs/2023-09-11-sulbutiamine/index.html#dosage-and-safety-studies-on-sulbutiamine",
    "href": "blogs/2023-09-11-sulbutiamine/index.html#dosage-and-safety-studies-on-sulbutiamine",
    "title": "Sulbutiamine - A Drug Review",
    "section": "Dosage and Safety Studies on Sulbutiamine",
    "text": "Dosage and Safety Studies on Sulbutiamine\nIn different regions of the World, Sulbutiamine is readily available as an over-the-counter drug supplement. It is presented for sale predominantly in two forms –bulk powder packs and capsules. Currently, there exists no definitive publication or official directive about the safety profile of Sulbutiamine in humans. However, long-term usage data has suggested that Sulbutiamine is generally tolerated in humans at doses up to 600mg/day. There are no reported cases of toxicity in humans. For safety concerns, it is advisable that this drug product be taken with food.\nContinuous use of Sulbutiamine for a period of time exceeding 4 weeks is unadvisable as the safety of its long-term use is unknown. Anecdotal reports of tolerance in humans has also been documented. Optimal dose for use is pegged at 200-600 mg taken twice or three times daily depending on indication for use and expert recommendation."
  },
  {
    "objectID": "blogs/2023-09-11-sulbutiamine/index.html#metabolism-and-excretion-of-sulbutiamine-in-humans",
    "href": "blogs/2023-09-11-sulbutiamine/index.html#metabolism-and-excretion-of-sulbutiamine-in-humans",
    "title": "Sulbutiamine - A Drug Review",
    "section": "Metabolism and Excretion of Sulbutiamine in Humans",
    "text": "Metabolism and Excretion of Sulbutiamine in Humans\nSulbutiamine is rapidly absorbed and distributed into the body tissues after oral administration. The lipophilic nature of the molecule ensures that it is accumulated in the tissues and also crosses the blood-brain barrier to effect neurotropic actions. Biochemical effects are noticed within 30 minutes of administration and peak effect is experienced after 3 hours. Sulbutiamine has a half-life of 5 hours and it is excreted mainly in the urine."
  },
  {
    "objectID": "blogs/2023-09-11-sulbutiamine/index.html#sulbutiamine-stacking",
    "href": "blogs/2023-09-11-sulbutiamine/index.html#sulbutiamine-stacking",
    "title": "Sulbutiamine - A Drug Review",
    "section": "Sulbutiamine Stacking",
    "text": "Sulbutiamine Stacking\nSulbutiamine stacking can also be done to maximize therapeutic response in humans. This emerging practice involves the combination of Sulbutiamine with drugs and drug products that can enhance its biochemical effects. The combination of Sulbutiamine with optimal doses of Cholinergics increases the central effect of Sulbutiamine on the cholinergic system. The adverse effects of some drugs are more pronounced when used for long periods in high doses. Sulbutiamine may be co-administered with suboptimal doses of these drugs to effects the needed clinical response with any significant adverse effect."
  },
  {
    "objectID": "blogs/2023-09-07-technology-based-intervention/index.html",
    "href": "blogs/2023-09-07-technology-based-intervention/index.html",
    "title": "Technology-based Intervention in Clinical Alcohol and Drug Addiction Care Programs",
    "section": "",
    "text": "Substance abuse and drug addiction constitute a major public health problem in different regions of the world. Interestingly, these problems are as old as the history of drug use and recently, different literature studies have made impressive attempts to study and specifically categorize drug use problems. In 2017, the National Survey on Drug Use and Health (NSDUH) reported an estimated value of 20 million people with an alcohol or drug use disorder. On a broad scope, dug use disorders are categorized as Opioid use disorder (OUD), Substance use disorders (SUD)and alcohol use disorders (“Chapter 8. Substance Use Disorders,” n.d.).\nAlcohol use disorders are the most widely documented addiction problems in the U.S and Europe. Regardless of the spectrum of designation, substance use disorders have been linked with increasing rates of psychiatric comorbidities including anxiety, suicidal tendencies and transient mood disorders. The societal and economic burden caused by these has necessitated scientific interest in the development of management plans and treatment options for drug addiction problems.\nTreatment options for substance abuse patients were developed and made prominently popular in the 20th century. Within a few years, a variety of management options based on psychosocial basis and behavioral observations have been developed and used as models for different randomized trials (Magill and Ray 2009). These conventional approach to treatment include brief intervention, community reinforced approach, motivational interviewing, contingency management, facilitated therapy and cognitive behavioral therapy.\nAs published, conclusions from this study suggests that these methods are effective in drug addiction care programs especially when paired with abstinence-contingent incentives. In 2009, the report of a meta-analysis randomized control trial studying the potency of cognitive-behavioral treatment on drug addiction patients was published by the Journal of Studies on Alcohol and Drugs (Paliwal, Hyman, and Sinha 2008). The conclusion of this report also supported early submissions and fueled the drive for novel treatment methods with more conclusive treatment outcomes.\nThe search for a novel treatment approach for use in drug addiction programs was intensified when reports of relapse and recurrent substance use increased. In 2008, the Journal of Drug and Alcohol Dependence published a report suggesting that the conventional approach to addiction therapy are susceptible to relapse and a high incidence of substance use recurrence. Technology-based therapy methods for drug addiction programs were developed and delivered through technological platforms including social network sites, smartphone applications websites and digital forums."
  },
  {
    "objectID": "blogs/2023-09-07-technology-based-intervention/index.html#digital-tools-for-therapists-in-addiction-care-programs",
    "href": "blogs/2023-09-07-technology-based-intervention/index.html#digital-tools-for-therapists-in-addiction-care-programs",
    "title": "Technology-based Intervention in Clinical Alcohol and Drug Addiction Care Programs",
    "section": "Digital Tools for Therapists in Addiction Care Programs",
    "text": "Digital Tools for Therapists in Addiction Care Programs\nCompared with the conventional methods, digital recovery services are readily available, convenient, privately delivered on a low budget, sustained over long durations and not necessarily delivered in a clinical setting (Boumparis, Schulte, and Riper 2019). Most importantly, these digital tools are linked with different technology-based methods of evaluating therapy effectiveness.\n\nSmartphone Applications\n\nDigital tools delivered on mobile phones are readily available, convenient for use, and can easily replace the face-to-face interviews and personal assignments of the conventional methods. Digital tools on smartphones are designed as advanced software platforms with varied functions and capabilities that supports a personalized addiction care plan. Modules on these applications increases patients’ awareness of their addiction problem, help patients assess daily alcohol use, document weekly recovery plans and provide a health publications detailing verified information about craving triggers and dangers of substance abuse (Dulin et al. 2013). Primarily, this digital intervention method offers users a coping strategy to reduce rate of hazardous drinking and also combat psychological distress that can cause relapse.\nThe Alcohol Comprehensive Health Enhancement Support System (A-CHESS) is a popular digital tool based on cognitive-relapse prevention technique, Marlette relapse-prevention system and a self-determination theory. Modules available for users include health information sources on addiction management, counselor support, self-assessment of recovery, and discussion groups. The cognitive-relapse prevention approach uses a GPS tracking prompts that remind users of their recovery goals on approaching a high-risk location. In 2013, Alcoholism Treatment Quarterly published a report examining theory and empirical evidence basis on smartphone-based, self-administered intervention system for alcohol use disorders. Results of the pilot randomized trial provided evidence of smartphone-based tools’ effectiveness in managing alcohol use disorders.\n\nInteractive Voice Recognition\n\nThe interactive voice recognition (IVR) digital technology is a modern adaptation of motivational interviewing. It involves a telephone-based delivery of recorded scripts guiding users on the methods of abstinence and recovery assessment. Scheduled phone calls are made by the therapist to addiction patients discussing techniques of medication adherence, craving management, adverse effect observations and monitoring of daily substance use. Voice prompts from the therapists elicit a participant’s real time response using voice feedbacks or keypad responses. A series of correctly answered responses helps the therapist with vital data recording for recovery evaluation.\nIn 2017, the International Journal of Behavioral Medicine published the report of a randomized controlled trial studying the effectiveness of interactive voice response with feedback intervention in outpatient treatment of substance use disorders. Study results suggests that personalized feedback potentially improves recovery from addiction problems and that IVR is useful for repeated intervention as an adjunct to regular treatment (Andersson et al. 2016). The therapist simply evaluates a stream of user-centered feedback to grade recovery and effectiveness of care plan.\n\nSocial Media and Online Forums\n\nOnline forums offer reinforced social support for patients enrolled in an addiction care program. The therapist creates a virtual community of online users interacting with a team of expert professionals in addiction therapy. Clinicians have taken a step further by forming social media chat rooms and discussion threads that offer virtual support on self-administered therapy plan, recovery tracking and other expert-delivered interventions for addiction management. Over the years, there is an increasing emergence of sites offering support networks, free customized abstinence plans and validated information on substance use problems. This sites include Women for Sobriety, SMART (Self-management and Recovery Training) and Sober Recovery.\nThe therapy idea for this tool is quite simple. These forums create a virtual interactive interface for the therapist and addicts. Therapists deliver a recovery goals and abstinence plans that suits a subgroup of enrolled participants. Participants reports addiction care data on daily substance use and substance craving frequency which helps the therapist track recovery and provide modifications of plans when necessary. Recently, different research reports supporting online forums as a viable digital tool for addiction programs has emerged. In 2014, National Institute on Drug Abuse has published an announcement detailing plans to fund different institutes exploring the use of social media and online forums to advance the scientific understanding of the management of substance use disorders and addiction problems."
  },
  {
    "objectID": "blogs/2023-09-07-technology-based-intervention/index.html#digital-tool-results-and-therapists-evaluations",
    "href": "blogs/2023-09-07-technology-based-intervention/index.html#digital-tool-results-and-therapists-evaluations",
    "title": "Technology-based Intervention in Clinical Alcohol and Drug Addiction Care Programs",
    "section": "Digital Tool Results and Therapists Evaluations",
    "text": "Digital Tool Results and Therapists Evaluations\nIn conventional methods of addiction therapy plans, blood tests and take-home assignments submitted by participants are important in evaluating the effectiveness of therapy. For instance, in Alcohol Use Disorder Identification Test (AUDIT), participants fill questionnaires that help therapists assess, tests and identify the presence of alcohol use disorders. In contrast, the effectiveness of technology-based addiction therapy tools can be self-assessed. Features and software modules designed with the recovery apps allows participants of an addiction programs to share real-time information about their recovery and abstinence program.\nFollowing voice prompt feedback, keypad responses or real-time mood reports, the therapist can assess determinants including high risk situations, abstinence violation, defective coping strategy, lifestyle imbalances and substance cravings. Information supplied allows the therapist to comprehensively understand participants’ recovery journey and offer modifications to improve therapy when necessary (Marsch, Carroll, and Kiluk 2014)."
  },
  {
    "objectID": "blogs/2023-09-07-technology-based-intervention/index.html#digital-tools-as-a-treatment-option",
    "href": "blogs/2023-09-07-technology-based-intervention/index.html#digital-tools-as-a-treatment-option",
    "title": "Technology-based Intervention in Clinical Alcohol and Drug Addiction Care Programs",
    "section": "Digital Tools as a Treatment Option",
    "text": "Digital Tools as a Treatment Option\nIn 2006, Addiction published a report article on the rate and predictors of alcohol relapse after treatment. Study results suggests that about 80% of treated participants in a drug addiction program who experience short-term remission are likely to relapse fully (Moos and Moos 2006). This study has fueled many scientific interests in the study of alcohol relapse rates and the use of digital tools as a mainstream therapy plan.\nTherapists have proposed a remote alcohol monitoring therapy that involves the combination of a suitable addiction digital tool with a breathalyzer. This provides a patient-focused plan that responsibly task participants with the provision of documented proof of sobriety and accountability for substance use. This plan simply increases the participants’ awareness of their substance use problem and puts them in charge of their recovery plan as the therapist provides periodic evaluation of monitoring plan. In updated assessment plans, digital tools can also present a relapse prevention model that completely replaces regular blood tests and evaluate immediate determinants and covert antecedents to substance use relapse (Marsch 2012).\nIncorporating digital tool into a monitoring plan as a treatment option reduces program entry barriers, eliminates geographic restrictions effects a lasting long-term personalized approach to addiction recovery. By extension, these tools have also been found to be effective in the management of depression and anxiety bouts secondary to substance use disorders. The drive for the inclusion of technology-based tools into primary healthcare has received wide commendation around the world. This plan offers a new interesting role to addiction therapists and widen the range of available tools for recovery plans. With continuous research and development of digital addiction tools, the benefits of technology-based interventions in addiction care programs are no doubt, far reaching."
  },
  {
    "objectID": "blogs/2023-08-01-cbd-blog/index.html",
    "href": "blogs/2023-08-01-cbd-blog/index.html",
    "title": "The Ultimate Comprehensive Guide for CBD Hemp Flower",
    "section": "",
    "text": "Cannabidiol has rapidly been gaining global attention, so we are sure you must have heard something about it. In the last decade, the public perception about cannabidiol and cannabidiol-containing products has changed significantly. This change is reflected in many pro-cannabis regulations that are currently active in many countries around the world. These regulations have positively impacted the global cannabis market, improving its valuation from $10.6 billion in 2018 to a projected valuation of over $63 billion by 2024 (Statista, 2019). Over the next 3 years or so, the cannabis industry is expected to see vast increases in cultivation, distribution, and its customer base."
  },
  {
    "objectID": "blogs/2023-08-01-cbd-blog/index.html#cannabidiol",
    "href": "blogs/2023-08-01-cbd-blog/index.html#cannabidiol",
    "title": "The Ultimate Comprehensive Guide for CBD Hemp Flower",
    "section": "Cannabidiol",
    "text": "Cannabidiol\nCannabidiol is a cannabinoid produced by Cannabis sativa (Indian Hemp) –an herbaceous plant native to Central and Western Asia. In the United Sates and many other pro-cannabis countries today, hemp - an industrial variation of cannabis sativa containing less than .3% THC, is the only legal source of cannabidiol. For many centuries, there have been different claims about the medical benefits of CBD derived from hemp. However, these claims remained largely unverified until the early 1970s. During this period, animal tests and a few human studies on the bioactivity of cannabinoids were conducted.\nEvidence from these studies make it easy to better understand how CBD and CBD-derived compounds can be beneficial in human medicine. Recent clinical studies have provided convincing evidence supporting the anxiolytic, analgesic, antipsychotic, neuroprotective, and antioxidant properties of CBD (Davies et al., 2019).\nYou might have heard about the CBD wonder drug ‘Epidiolex.’ In June 2018, the Food Drug Administration approved Epidiolex as the first CBD-based drug for the management of rare, severe epilepsy (Sekar., 2019). With one FDA approved CBD drug being approved by the FDA on the market, you can assume that the volume of research currently dedicated to developing new CBD products for use in humans is high – which it is. Studies on CBD have gone up drastically in the last few years since it was legalized in the US."
  },
  {
    "objectID": "blogs/2023-08-01-cbd-blog/index.html#cbd-hemp-flower",
    "href": "blogs/2023-08-01-cbd-blog/index.html#cbd-hemp-flower",
    "title": "The Ultimate Comprehensive Guide for CBD Hemp Flower",
    "section": "CBD Hemp Flower",
    "text": "CBD Hemp Flower\nThe Cannabis sativa plant is a dynamic plant with many useful parts. You can say every part of the cannabis plant serves a purpose and are sold for different value on the cannabis market. CBD hemp flower is on of the most sought after cannabis products. It is described the dried or raw hemp flower buds of the cannabis plant, containing less than 0.3 percent THC. CBD hemp flower can be sold under different names, including cannabis flower, hemp flower, CBG flower, and CBD flower.\nIn some countries, cannabis products with THC levels below 0.3 percent THC are classified as legal marijuana. CBD hemp flower contains no significant amounts of calories, fat cholesterol, lactose, and trans fat. Depending on the strain, hemp flowers can bloom and store variable quantities of secondary cannabinoids, flavonoids, and terpenes. The flavonoid content of the hemp flower imparts the potent flavors and smell of the flower. Secondary cannabinoids are those cannabadinoid that are not THC or CBD in the cannabis sativa plant. Flavonoids and are contents of the hemp flower that imparts the vaious flavours and scents in the cannabis strains. Terpenes on the other hands, serves multiple multiple purposes –they imparts on flavor and complements the bioactivity of the principal cannabinoids in humans.\nIn the US, thanks to the Hemp Farm Bill of 2018, CBD derived from hemp plants that contains less than .3% thc, is legal and able to be sold in all 50 states. Depending on where you are located or where you are buying your hemp flower from, you can run into many different names for it: cbd hemp flower, cbd flower, cbg flower, hemp buds, and hemp cbd flower. Hemp flower is produced by cultivating the feminized hemp flower seeds in a greenhouse, indoor, or oudoor agriculture growing operation. Just like marijuana, hemp flower has many different strains, and each strain has a different compostion of the cannaboids, flavonoids, and terpenes.\nAn important feature of hemp flower you should never miss is its unique composition. You might have purchased a few cannabis products from the market and notice that some of these products are marked ‘full-spectrum cannabis products.’ As full-spectrum products, they are formulated from the cannabis plant and include compounds from the whole hemp plant. In essence, these products were not simply isolated cannabis compounds. Hemp flowers fall in this category. Depending on the cannabis strain, it contains a residual, THC, terpenes, and other phytocannabinoids that make using hemp flower instead of pure CBD an experience to relish.\n\nDifferenciating Between CBD and Hemp Flower\nRecently, the global cannabis consumer market noticed steady upticks in demand for CBD hemp flower. These demands were reasonably fueled by increased pro-cannabis regulations and the increased research reports on CBD hemp flower. Cannabis users simply desired to test this new method of consuming their favorite weed strain. As it stands, the demand for cannabis hemp flower is predicted to remain high, contributing to the projected market valuation of the global cannabis market in 2024 (Grand View Research, 2021).\nScientific inquiries into the properties of hemp flowers have also created new answers for cannabis enthusiasts about hemp flowers. However, these researches have also directly increased the public awareness of the medical and recreational benefits. So, how do you better understand what hemp flowers offer? What, if any, are the main differences between CBD hemp flower and CBG hemp flower? These questions should enlarge your horizon about the endless usage benefits of cannabis hemp flower also make you appreciate the mother plant better. The most widely researched and documented differences between CBD and CBG hemp flower include:\n\n1. Visual Features\nThis is perhaps the first difference you would notice between two cannabis products labeled as ‘CBD hemp flower’ and ‘CBG hemp flower.’ The visual features of the CBD hemp flower depend much on the strain from which it is derived. So, the appearance of the buds might be different across strains. CBG hemp flower, on the other hand, has more delicate trichomes than CBD hemp flower. Cannabis farmers take extra precautions during harvesting and curing to ensure that these trichomes are preserved in their original state.\n\n\n2. Phytocannabinoid Composition\nCannabis sativa contains over 400 phytocannabinoids present in pure and bounds forms with other compounds. These compounds are either singly or jointly responsible for the bioactive properties of cannabis and cannabis-derived products. These compounds are present in different quantities in different extracts and derivatives of the parent plant. Phytochemical distribution on a growing cannabis plant varies extensively (Andre et al., 2016). The hemp stem, leaf, bud, and trichomes have different phytocannabinoid distribution.\nCBD hemp flower and CBG hemp flower are different primarily in their dominant cannabinoid composition. CBG is directly derived from CBGA – a carboxylic acid that can form other cannabinoids. CBG flowers are derived from cannabis strains that are high in CBG. This makes CBG (Carbigerol) the dominant cannabinoid in the CBG hemp flower. In CBD hemp flower, however, cannabidiol (CBD) is the dominant cannabinoid.\n\n\n3. Slightly different Bioactivity\nCBD has been around for many years. Unlike CBD hemp flower, the focus on CBG hemp flower started a few years ago. These hemp types may have slightly different effects on cannabis users. Many reports are suggesting that CBG hemp provides a more energizing effect than CBD hemp flower. CBG hemp flower is also recommended as adjunct treatment of bacterial infections (Giovanni., 2008). However, the effects of CBG hemp flower in humans are not as pronounced and steady as with CBD hemp flower. The availability of each type of hemp flower is another primary difference between these products."
  },
  {
    "objectID": "blogs/2023-08-01-cbd-blog/index.html#medical-benefits-of-cbd-hemp-flower",
    "href": "blogs/2023-08-01-cbd-blog/index.html#medical-benefits-of-cbd-hemp-flower",
    "title": "The Ultimate Comprehensive Guide for CBD Hemp Flower",
    "section": "Medical Benefits of CBD Hemp Flower",
    "text": "Medical Benefits of CBD Hemp Flower\nThe research evidence supporting the medical and recreational use of CBD hemp flower keeps increasing by the day. Medical inquiries into the cannabis plants are aimed at better understanding the pharmacology of cannabinoids and how they affect human physiology. Most of these studies examined the mechanism of interaction between the biological system in humans and the cannabinoids of the cannabis plant. Do you know the body has its system of circulating ‘natural cannabinoids’? These chemicals are called endocannabinoids.\n\n\n\n\n\n\nClaims\n\n\n\nUnlike in the early days of unverified claims about the benefits of CBD and other cannabinoids, we now have pharmacological explanations for the effects of these compounds in biological systems"
  },
  {
    "objectID": "blogs/2023-08-01-cbd-blog/index.html#claims",
    "href": "blogs/2023-08-01-cbd-blog/index.html#claims",
    "title": "The Ultimate Comprehensive Guide for CBD Hemp Flower",
    "section": "Claims",
    "text": "Claims\nUnlike in the early days of unverified claims about the benefits of CBD and other cannabinoids, we now have pharmacological explanations for the effects of these compounds. :::"
  },
  {
    "objectID": "blogs/2023-08-01-cbd-blog/index.html#how-cannabinoids-interact-with-the-human-body",
    "href": "blogs/2023-08-01-cbd-blog/index.html#how-cannabinoids-interact-with-the-human-body",
    "title": "The Ultimate Comprehensive Guide for CBD Hemp Flower",
    "section": "How Cannabinoids Interact with the Human Body",
    "text": "How Cannabinoids Interact with the Human Body\nCannabinoids of the cannabis plant interact with the body by mimicking the effects of the endocannabinoids. Endocannabinoids are structurally complex biological compounds made of amides, esters, and other derivatives of long-chain polyunsaturated compounds. Produced on-demand from lipid constituents of the body cells, these compounds act as biological mediators in cell signaling processes (Zou., 2018). They are relatively unstable and sometimes produce no significant systemic action. Endocannabinoids and the enzymes responsible for their production and deactivation make up a complex biological network of the Endocannabinoid System (ECS).\nThe cannabinoid receptors provide a biological action point for the endocannabinoids on numerous target organs where they are present. Cannabinoids, including CBD and THC, act on these receptors to effect a biological action. This is why your favorite cannabis strains give you the euphoria, calms, and other recreational benefits you enjoy."
  },
  {
    "objectID": "blogs/2023-08-01-cbd-blog/index.html#takeaway-considering-buying-cbd-hemp-flower",
    "href": "blogs/2023-08-01-cbd-blog/index.html#takeaway-considering-buying-cbd-hemp-flower",
    "title": "The Ultimate Comprehensive Guide for CBD Hemp Flower",
    "section": "Takeaway: Considering Buying CBD Hemp Flower?",
    "text": "Takeaway: Considering Buying CBD Hemp Flower?\n\n1. CBD Hemp Flower Gives You Flexibility and Variety in Cannabis Usage\nThis is perhaps the single most important reason you should consider switching to CBD hemp flower. Presenting cannabis as the hemp flower helps you creatively use the plant. Hemp flowers can be smoked like tobacco or incorporated into food products. The latter method of usage is the branding idea behind a new line of cannabis products –cannabis edibles. The dried hemp flower can be hand-rolled and smoked like a regular cannabis joint. When incorporated into food, the buds are mixed into a recipe, then cooked or baked.\nCBD, like THC and other phytochemicals present in the CBD hemp flowers, are soluble in fat. Infusing these products into oil or butter is a recommended method of consuming cannabis as a food.\n\n\n2. CBD Hemp Flower Gives the Entourage Effect\nCannabis users provide feedbacks describing the effects of many strains. This feedbacks help botanists and cannabis researchers to better understand and classify the different cannabis strains available today. Anecdotal reports from different users suggest that the ‘full spectrum’ cannabis products, by an unknown mechanism, exert a better therapeutic effect in humans compared to isolated CBD. David Mechoulam –the famous father of cannabis research, proceeded to investigate this claim and discovered the ‘Entourage Effect.’ The effect is a proposed mechanism explaining how THC acts in synergism with other components of the cannabis plant to modulate the biochemical effects of cannabis in humans.\nIn 2011, the British Journal of Pharmacology published the report of a study confirming that selective breeding of cannabis chemotypes rich in phytocannabinoids offer complementary effects that strengthen the therapeutic properties of cannabis extracts (Russo., 2011). This report confirmed the entourage effect earlier described by Mechoulam. Unlike pure CBD isolates, CBD hemp flower contains a trace amount of these phytocannabinoids. The medical and recreational benefits of using CBD hemp flower are pronounced compared with pure CBD isolates."
  },
  {
    "objectID": "blogs/2023-08-01-cbd-blog/index.html#faqs-on-hemp-flower",
    "href": "blogs/2023-08-01-cbd-blog/index.html#faqs-on-hemp-flower",
    "title": "The Ultimate Comprehensive Guide for CBD Hemp Flower",
    "section": "FAQs on Hemp Flower",
    "text": "FAQs on Hemp Flower\n\nWhat Percentage of CBD Should Hemp Flower Have\n\nThe CBD content of hemp flowers depends on the cannabis strains from which the hemp flower is produced. However, CBD hemp flower with a CBD content of 20% or more is considered a premium product.\n\nWhat is CBD Hemp Flower Used for?\n\nCBD hemp flower serves multiple purposes for both recreational and medical cannabis users. You can include it in your food recipe or simply smoke it as a joint. In medical science, it is recommended as a complementary therapy for the management of anxiety, sleep disorders, and pain. You can buy wholesale hemp flower online easily.\n\nHow Much CBD Hemp Flower Would it Take to Fail a Drug Test?\n\nCBD hemp flower contains high quantities of the non-psychoactive cannabinoid –CBD and very low quantities of the psychoactive cannabinoid –THC. Consuming high levels of THC can make you fail a drug test. We advise that you use hemp flowers responsibly as recommended by your doctor or pharmacist.\n\nHow Much CBD Hemp Flower Gives a full Medical/Recreational Effect?\n\nThere are no recommended dosing standards for CBD products as these products are still under human research trials. However, we advise you to start with a low quantity of CBD hemp flowers. You can increase this quantity gradually until you get the lowest amount that gives the desired effect. You can also consult your doctor on this.\n\nWhat is the Best CBD Flower for Relaxation\n\nYou might want to consider Hawaii Haze for its high levels of CBD and terpenes –Myrcene, Caryophyllene, Bisabol, and Borneol. It gives you a full-body relaxation effect with waves of warm citrus and sour diesel flavors. Super Sour Candy also provides a good relaxation effect."
  },
  {
    "objectID": "blogs/2023-07-21-ckd-case-study/index.html",
    "href": "blogs/2023-07-21-ckd-case-study/index.html",
    "title": "Plant-Based Dietary Approach in the Management of Third Stage Chronic Kidney Diseases",
    "section": "",
    "text": "Abstract\n\n\n\nChronic kidney disease is associated with increasing age, diabetes, cardiovascular diseases, and drug use. In Norway, USA and Australia, large scale screening programs undertaken in the 2000s indicated that more than 10% of the adult population have markers for chronic kidney disease [coresh2003?,chadban2003?,hallan2006?]. By 2030, the number of people on renal replacement therapy is expected to reach 5.4 million. About 2.3 – 7.1 1 million adults have reportedly died prematurely from lack of access to renal replacement therapy services3.\nIn a bid to properly check the prevalence and mortality rate of CKD, different national and international agencies have adopted strategies aimed at reducing the global burden of CKD. NSAIDs are commonly used in the general population for the control of pain associated with inflammation and migraine. This clinical case study describes a 55-year-old man with a confirmed diagnosis of CKD. He was prescribed an NSAID to manage his cluster headache. However, long term use of this NSAID worsened the CKD. His CKD resolved completely with dietary intervention and he subsequently halted the use of the NSAID."
  },
  {
    "objectID": "blogs/2023-07-21-ckd-case-study/index.html#case-introdudction",
    "href": "blogs/2023-07-21-ckd-case-study/index.html#case-introdudction",
    "title": "Plant-Based Dietary Approach in the Management of Third Stage Chronic Kidney Diseases",
    "section": "Case Introdudction",
    "text": "Case Introdudction\nChronic kidney disease describes long-tern loss of the kidney functions. It is generally characterized by kidney damage, abnormal albumin excretion and decreased kidney functioning persisting for more than three months. Therapy plans for CKD are comprehensive and require a systematic monitoring of Kidney function. In 2002, the Kidney Disease Outcomes Initiative (KDOQI) of the National Kidney Foundation defied the decreased kidney function in CKD as that of a glomerular filtration rate less tan 60mL/min/1.73m22. Reduction in the glomerular filtration rate is linked to the loss of functional nephrons and the reduction in renal mass. The most commonly documented complications associated with CKD include anemia, renal ostedystrophy, left ventricular hypertrophy and congestive heart failure.\nThe KDOQI guidelines classified CKD progression into five different stages for informed patient management. Patients at stages 1 (normal eGFR&gt;= 60 mL/min/1.73m2 with persistent albuminuria), stage 2 (eGFR between 60-89 mL/min/1.73m2) and stage 3 (eGFR between 30-59 mL/min/1.73m2) are generally asymptomatic. At stage 4 (eGFR between 15-29 mL/min/1.73m2) and stage 5 (eGFR &lt;15mL/min/1.73m2 w), patients experience symptoms suggesting metabolic acidosis, electrolyte imbalance and endocrine derangements. In suspected cases, establishing a confirmed diagnosis for CKD involves conducting laboratory studies that directly measures kidney functioning. These includes serum albumin levels tests, lipid profile, urinalysis basic metabolic profile and complete blood count.\nClinical reviews and studies have implicated NSAIDs in the onset and progression of CKD. No steroidal anti-inflammatory drugs are commonly prescribed for analgesic and anti-inflammatory effects in people with CKD. In the general adult population of the U.S., one in fifteen adults are actively medicating on NSAIDs. This class of drugs can limit renal blood flow, induce cytotoxicity, limits cell-mediated immune injury response and cause tubular obstruction through crystal formation and deposition. These adverse drug effects of NSAIDs have been linked with the onset of CKD in healthy patients. Dietary interventions are becoming popular as supplementary or alternate therapy in the management of CKD. A low protein diet has been shown to improve the symptoms of CKD and also noticeably improve kidney functioning."
  },
  {
    "objectID": "blogs/2023-07-21-ckd-case-study/index.html#clinical-case-study",
    "href": "blogs/2023-07-21-ckd-case-study/index.html#clinical-case-study",
    "title": "Plant-Based Dietary Approach in the Management of Third Stage Chronic Kidney Diseases",
    "section": "Clinical Case Study",
    "text": "Clinical Case Study\nThe patient is a 55-year-old man who presented to a Secondary Health Care Facility on account of Gastroesophageal Reflux Disease (GERD) and Chronic Kidney Disease in October 2019. Patient present with a Stage 3 CKD characterized by eGFR of approximately 50 mL/min/1.73m2. He had no history of diabetes, hypertension, pulmonary venous disease, urinary tract disease cardiovascular disease or acute kidney infection. He stopped smoking about 35 years ago and had no known exposure to lead.\nBefore presentation, he had visited 3 nephrologists who confirmed that his CKD was triggered by his long history of medicating on non-steroidal anti-inflammatory drugs (NSAIDs). A review of his medication history revealed that he has been on Indomethacin (25mg 12hrly) for the management of cluster headache. The patient started medicating on Indomethacin since 2005, and ALEVE (??) before 2005. After the consultation, the patient consented to a diet-based intervention for symptomatic control of CKD. He lives a sedentary lifestyle and has no family history of Kidney disease. Diet therapy was designed as Standard American Diet involving a decreased intake of processed food, more animal protein and an increased consumption of more fruits and vegetable units daily.\nIn February 2020, the patient reported a controlled GERD and had reduced the dosage of indomethacin to 25 mg once daily. He was also switched from Omeprazole to Ranitidine as a maintenance therapy for the resolving GERD. Three months later, the frequency of indomethacin administration was reduced to 3-4 times daily and the patient commenced an 80% plant-based diet. By December 2020, the patient was taken off Ranitidine as GERD had completely resolved. Indomethacin usage frequency was readjusted to once or twice in a week as the cluster headache had resolved significantly with no single flare up. The patient was commenced on a 90% plant-based diet with fruits and vegetables constituting about 8 servings per day.\n\n\n\nFig. 1: Laboratory results showing eGFR normalization trend in the patient\n\n\ntidyverse?\n\n\n\nFig.2: Creatinine level variation in the patient"
  },
  {
    "objectID": "blogs/2023-07-21-ckd-case-study/index.html#discussion",
    "href": "blogs/2023-07-21-ckd-case-study/index.html#discussion",
    "title": "Plant-Based Dietary Approach in the Management of Third Stage Chronic Kidney Diseases",
    "section": "Discussion",
    "text": "Discussion\nThere is an accumulated volume of scientific evidence linking long-tern use of NSAIDs to the onset and progression of CKD. The 2008 National Institute of Health and Clinical Guidelines considers NSAIDs to be nephrotoxic and further contradicted its use in CKD patients. Dietary interventions have been proposed by many clinical studies as an alternate therapy for CKD remission in many patients. This is especially important in cases with multiple risk factors. In addition to a long-tern use of Indomethacin (an NSAID) this patient was on a default diet of high animal protein and diary.\nAccording to the United States National Academy of Medicine, the Recommended Dietary Allowance (RDA) of protein is pegged at 0.8g/kg/dad. However, on an average the US adult population consumes higher protein –about 1.3 -1.4 g/kg/day –largely from animal sources. Recent researches examining the link between Kidney health and high animal protein diets have suggested that these meals should be discourages in people with kidney diseases. Dietary protein intake in these diets increases intra-glomerular pressure with resultant glomerular hyper-filtration5. Compounded with long tern NSAIDs use, these diets increase the risk and progression of chronic kidney disease1.\nIn a sharp contrast a low protein diet with a Dietary Protein Intake (DPI) range of 0.6-0.8g/kg/day has been verified to lower intra-glomerular pressure in CKD patients6. When maintained over a long period of time, low protein diets with DPI lower than the initial recommendation can effect even slower progression of CKD in many patients4. In another resent meta-analysis of dietary trials in CKD patient, researchers confirmed that low protein diets are associated with lower End Stage Kidney Disease risk, lower serum phosphorus levels, higher serum bicarbonate and lower mortality rate in CKD patients7.\nIn this case study, dietary intervention for the management of chronic kidney disease was balanced on plant-based diets. Lin et al (11) provided an early evidence supporting plant-based diets as effective interventions in CKD patients. A later study conducted by Kim et al (12) confirmed that plant-based diet is associated with favorable kidney outcomes. Unlike previous studies, Kim et al used a large participant poll – 14,686 middle-aged adults –to strengthen the support of plant-based diets in decreasing the rate of progression of CKD.\nThe patient was placed initially on an 80% plant-based diet which was steadily increased to 90%. During this period, the daily servings of fruits and vegetables increased to 7-8 and animal-based protein was completed removed from the patient’s diet. This diet regimen improved the eGFR1 significantly from approximately 50 mL/min/1.73m2 at admission to &gt;60 mL/min/1.73m2 as at last clinical appointment. The creatinine level also decreased significantly to less than 1.2. The cluster headache prompting the need for Indomethacin (an NSAID) also completely resolved.\nThis case study provided further scientific support for plant-dominant low-protein diet as a dietary approach in the management of Chronic Kidney Disease. However, many patients remain uninformed about the role of diet in the reduction of the rate of CKD progression. CKD-specialized dietitians have a major role to play in increasing awareness for diet approaches in the management of Chronic Kidney Disease. Awareness is needed in the general population, regions with vulnerable population and among clinicians in general."
  },
  {
    "objectID": "blogs/2023-10-01-breathalyzers/index.html",
    "href": "blogs/2023-10-01-breathalyzers/index.html",
    "title": "Breathalyzers in Clinical Alcohol and Drug Care Programs",
    "section": "",
    "text": "Substance abuse has long been described by many observers and stakeholders in the medical sphere as a plague ravaging the world. Regardless of population demographics, health disparities and cultural perspective on controlled substance use, there are emerging data indications suggesting that the menace cuts across different nationality, ethnicity and professional background.\nOver the last decade, regions where strict regulations are not enacted to curb substance abuse has witnessed an unprecedented rise in domestic crimes and organized gang-related crimes. Beyond the widely known health implication of excessive alcohol use and substance abuse, reduced productivity associated with a rapidly increasing economic burden has also been linked with excessive alcohol use and substance abuse.\nIn 2015, the American Journal of Preventive Medicine published a review articles examining the National costs and excessive alcohol consumption in the United States. Data sources, as revealed, indicated that the economic cost of excessive alcohol use amounts to a staggering $249 billion in 2010. However, the total cost –including cost to government, estimated cost of binge drinking, gestational alcohol use, and underage drinking –reduced steadily to around $223.5 billion in 2006.\nAcross Europe, regulations on alcohol use has been helpful in controlling substance abuse and incidence of substance use disorders among the population. Strategies currently used by government agencies in limiting alcohol use includes increased taxation on alcohol products, reduced alcohol outlet density, and the introduction of strict licensing modalities for commercial retailers."
  },
  {
    "objectID": "blogs/2023-10-01-breathalyzers/index.html#global-trends-in-alcohol-use-and-substance-abuse",
    "href": "blogs/2023-10-01-breathalyzers/index.html#global-trends-in-alcohol-use-and-substance-abuse",
    "title": "Breathalyzers in Clinical Alcohol and Drug Care Programs",
    "section": "",
    "text": "Substance abuse has long been described by many observers and stakeholders in the medical sphere as a plague ravaging the world. Regardless of population demographics, health disparities and cultural perspective on controlled substance use, there are emerging data indications suggesting that the menace cuts across different nationality, ethnicity and professional background.\nOver the last decade, regions where strict regulations are not enacted to curb substance abuse has witnessed an unprecedented rise in domestic crimes and organized gang-related crimes. Beyond the widely known health implication of excessive alcohol use and substance abuse, reduced productivity associated with a rapidly increasing economic burden has also been linked with excessive alcohol use and substance abuse.\nIn 2015, the American Journal of Preventive Medicine published a review articles examining the National costs and excessive alcohol consumption in the United States. Data sources, as revealed, indicated that the economic cost of excessive alcohol use amounts to a staggering $249 billion in 2010. However, the total cost –including cost to government, estimated cost of binge drinking, gestational alcohol use, and underage drinking –reduced steadily to around $223.5 billion in 2006.\nAcross Europe, regulations on alcohol use has been helpful in controlling substance abuse and incidence of substance use disorders among the population. Strategies currently used by government agencies in limiting alcohol use includes increased taxation on alcohol products, reduced alcohol outlet density, and the introduction of strict licensing modalities for commercial retailers."
  },
  {
    "objectID": "blogs/2023-10-01-breathalyzers/index.html#elements-of-clinical-alcohol-and-drug-addiction-care-programs",
    "href": "blogs/2023-10-01-breathalyzers/index.html#elements-of-clinical-alcohol-and-drug-addiction-care-programs",
    "title": "Breathalyzers in Clinical Alcohol and Drug Care Programs",
    "section": "Elements of Clinical Alcohol and Drug Addiction Care Programs",
    "text": "Elements of Clinical Alcohol and Drug Addiction Care Programs\nVarious care programs and awareness campaigns have been activated in some regions based on therapy methods that have been confirmed to be effective over the years. Prevention modalities are a basic part of clinical alcohol and drug addiction care programs. These care programs are designed as a patient-focused approach incorporating pharmacotherapy plans with digital tools and hardware measuring tools to evaluate therapy. Currently, the newly recommended plan for alcohol addiction programs involves the fusion of psychotherapy and technology-based intervention (TBI) methods. TBIs in people with alcohol dependence in channeled in a two-way approach that encompasses digital support programs, alcohol blood level measurement and addiction treatment.\nThe role of technology-based interventions in reducing the rate of alcohol consumption are somewhat questionable and also complicated when discussed. However, the idea basically involves taking advantage of advancement in digital technology to drive the campaign against irresponsible use of alcohol products. Text messaging, interactive voice-recognition, and smart phone apps are the leading examples in this domain. In 2013, an early study evaluating the effectiveness of technology-based interventions in primary care settings for substance use programs was published by PLOS Medicine. Conclusions derived from over 75 controlled trials published in the review suggests that these methods improved the rate of patient adherence to therapy plans in substance abuse programs. This study has since scored a significant point for the inclusion of TBIs in alcohol care programs. Most importantly, technology-based interventions now replace traditional methods of evaluating alcohol use with rapid, convenient, and sensitive methods. Perhaps, the major setback to traditional methods of measuring blood alcohol levels is the limitation in accuracy. These methods are also considered to be relatively low on sensitivity and hence can be inadequate in substance-specific testing. Participants in clinical alcohol care programs often consider urine tests, as with other traditional methods, to be inconvenient and inefficient for document abstinence rate in continued-care programs.\nAs expected, clinical evaluation of alcohol use and rate of adherence to care programs are determined by measuring the level of blood alcohol content (BAC). The difficulties presented by traditional methods have fueled a quest for the development of modern methods based on technological innovations. Until recently, urine test and laboratory blood analysis are the main methods of measuring BAC.\nWith advances in technology-based interventions, breathalyzers have been developed as a modern approach to measuring BAC. Breathalyzers are sensitive digital hardware tools that can detect blood alcohol content and produce on-the-spot reproducible results. The different breathalyzer brands currently available in the market generally uses any of three innovative technologies –Fuel cell testers, Infrared Spectrometer, and Semiconductor oxide-based testers."
  },
  {
    "objectID": "blogs/2023-10-01-breathalyzers/index.html#breathalyzers-in-clinical-alcohol-and-drug-addiction-care-programs",
    "href": "blogs/2023-10-01-breathalyzers/index.html#breathalyzers-in-clinical-alcohol-and-drug-addiction-care-programs",
    "title": "Breathalyzers in Clinical Alcohol and Drug Care Programs",
    "section": "Breathalyzers in Clinical Alcohol and Drug Addiction Care Programs",
    "text": "Breathalyzers in Clinical Alcohol and Drug Addiction Care Programs\nDigital hardware tools are the new addition to residential and in-patient treatment plans for substance abuse patients. These tools evaluate adherence and provides a remote support for patients on substance use disorder treatments and addiction care plans. It is now common to find government-sponsored programs using hardware tools in facilitating routine workshops, individual and family counselling, and individualized use plans as regards alcohol and drug monitoring.\nAs regards alcohol addiction, breathalyzers help patients embrace sobriety and recover quickly from addiction. Breathalyzers and other hardware tool in substances use evaluations are becoming increasingly popular in the U.S and Europe. In 2019, the Wall Street Journal published an article review of DynamiCare Health –an evidence-based platform that supports and reward substance abuse patients on a deliberate path to recovery. This article also included comments on the infusion of cash by venture capitalists into startups focused on developing novel hardware and digital-based tools for use in alcohol addiction programs. Unfortunately, a lot of people still consider hardware tools especially breathalyzers as devices merely used in DUI cases.\nSemiconductor oxide-based breathalyzers uses an ethanol-sensitive sensor to detect and measure BAC. By using a tin-oxide material cheaper than platinum fuel cell sensor technology, this breathalyzer brands are particularly useful in self-monitoring of blood alcohol content. Customized brands of this same technology is used by labs and low-volume professional testing agents in alcohol testing procedures. Fuel cell breathalyzers are portable, sensitive and extremely sensitive.\nRelying on an electrochemical process, the fuel cell consists of two platinum electrodes and a porous acid-electrolyte setup. Platinum oxidizes the alcohol content present in a stream of exhaled breath and produces protons, electrons and acetic acid. Electrons, as an indication of current, flows through a circuit setup and provides a reproducible estimate of the blood alcohol content. Fuel cell sensors are used by law enforcement officers for roadside alcohol screening and by clinics and primary care centers managing alcoholics. Breathalyzers based on the techniques of infrared spectrometry are large and are mainly suitable for confirmatory tests of independent results of BAC. Alcohol content in a sample is analyzed by determining the rate at which alcohol molecules absorbs infrared light of a specific wavelength."
  },
  {
    "objectID": "blogs/2023-10-01-breathalyzers/index.html#blood-alcohol-content-bac-testing",
    "href": "blogs/2023-10-01-breathalyzers/index.html#blood-alcohol-content-bac-testing",
    "title": "Breathalyzers in Clinical Alcohol and Drug Care Programs",
    "section": "Blood Alcohol Content (BAC) Testing",
    "text": "Blood Alcohol Content (BAC) Testing\nBlood alcohol content testing is important in medical and legal foregrounds. BAC results reveal the level of alcohol in the blood as direct measurement of intoxication level and impairment. Depending on volume consumed, impairments associated with heavy alcohol includes impairment in depth perception, reasoning, peripheral vision, reflexes, and gross motor skills. In Europe and many states of the U.S., drivers and operators of heavy machinery are considered legally intoxicated at a BAC level of .08% and above.\nResults lower than this threshold can be interpreted in relation to the impairments associated with the BAC level. For instance, at 0.02%, a user might be judged to have an impaired sense of judgment, and at .05%, a user might be judged to have lost control of the small muscles resulting in reduced alertness and poor coordination during physical activities. At .08%, the impairment noticed include loss of balance, slower reaction rate, slurred speech, loss of visual acuity, loss of hearing and difficulty in detecting danger. With loss in visual acuity and reduced reaction time, a driver finds it difficult to control speed limit or recognize traffic signals.\nImpairments are more pronounced at a BAC level of .10% as it becomes difficult for drivers under the influence to maintain lane position or machinery operators under the influence to recognize the right controls. At .15% and above, there is loss of consciousness and memory with an associated breathing difficulty that can eventually leads to death. These evaluations are important in legal cases bordering on determining BAC levels ."
  },
  {
    "objectID": "blogs/2023-10-01-breathalyzers/index.html#bac-testing-might-be-required",
    "href": "blogs/2023-10-01-breathalyzers/index.html#bac-testing-might-be-required",
    "title": "Breathalyzers in Clinical Alcohol and Drug Care Programs",
    "section": "BAC Testing Might be Required",
    "text": "BAC Testing Might be Required\nIn most cases, BAC test results are ordered in legal proceedings as evidences for crimes committed under the influence. It is common practice in different countries to order for a BAC test immediately after an auto crash with the possibility that alcohol might play a major role in cognitive impairment. BAC results might also be ordered as a part of random drug test at workplaces and in organized sporting activities. Some life insurance policies also require that the insured presents periodic BAC results that proves abstinence from alcohol. In all these instances, the point is to prove sobriety and abstinence from alcohol use.\nIn medical practice, on-the-spot BAC tests might be required to ascertain the remote cause of confusion or poor coordination. BAC tests are particularly important in clinical alcohol and drug addiction programs. Subsequent tests performed over a period of time can adequately evaluate the effectiveness of a technology-based intervention (TBI) method adopted for an addiction care plan. In a continued-care plan, reliable alcohol tests assess the level of after-care abstinence from alcohol, recovery rate and alcohol consumption rate monitoring."
  },
  {
    "objectID": "blogs/2023-09-11-sulbutiamine/index.html#adverse-effects-and-drug-interaction",
    "href": "blogs/2023-09-11-sulbutiamine/index.html#adverse-effects-and-drug-interaction",
    "title": "Sulbutiamine - A Drug Review",
    "section": "Adverse Effects and Drug Interaction",
    "text": "Adverse Effects and Drug Interaction\nAs with other popular supplements, Sulbutiamine is considered safe when used at the standard dose regimen under expert supervision. It is generally advisable that users of this product adopt a cyclic method of dosing. This involves intermittent breaks or drug-free days in between usage periods. In this usage plan, Sulbutiamine is administered consistently for 3 days before a day off. It has been found to moderately interact with antibiotics.\nA study published by the Journal of Association of Physicians of India reported drug interaction adverse effects in about 0.6% of patients treated with a combination of Sulbutiamine and specific anti-infective drugs. There is little documentation about the side effects of Sulbutiamine in humans. These side effects are infrequent and can include euphoria, headaches, mild agitation, nausea, insomnia, tremor drowsiness and skin allergies. Unless otherwise recommended by a physician, Sulbutiamine is contraindicated for use in pregnancy."
  },
  {
    "objectID": "data/index.html",
    "href": "data/index.html",
    "title": "'Kolade Gracious",
    "section": "",
    "text": "While Navigating…..\n\n\n\n\nAccess all data projects with the sub-links posted under each post. Report on issues, queries and clarification on Github\n\n\n\n\n\n\n\n\n\n\n    \n      Analyzing U.S Financial Aid to Africa's 7 Largest Economies [2019 - 2022] \n      \n      \n      \n        \n          Jun 26, 2023. 'Kolade Gracious.\n        \n      \n      \n         \n           LinkedIn \n         \n         \n           GitHub Code \n        \n         \n           Twitter Post \n         \n      \n      \n      \n    \n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n    \n      Returning Multi-Level Aggregates in PostgreSQL Using ROLLUP Function \n      \n      \n      \n        \n          Aug 1, 2023. 'Kolade Gracious.\n        \n      \n      \n         \n           LinkedIn \n         \n         \n           Medium \n        \n      \n      \n      \n    \n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n    \n      Creating a Comprehensive Date Table for Time Intelligence Analysis in R \n      \n      \n      \n      \n        \n          Oct 8, 2023. 'Kolade Gracious.\n        \n      \n         \n           Read on Quarto \n         \n         \n           LinkedIn \n         \n         \n           Twitter Post \n         \n      \n      \n      \n    \n    \n      The Bellabeat Case Study: Analyzing Trends in Smart Device Usage \n      \n      \n      \n      \n        \n          Dec 15, 2022. 'Kolade Gracious.\n        \n      \n         \n           Read on Kaggle \n        \n         \n           GitHub Code \n        \n      \n      \n      \n    \n\n\nNo matching items"
  },
  {
    "objectID": "data/index.html#r",
    "href": "data/index.html#r",
    "title": "'Kolade Gracious",
    "section": "R",
    "text": "R\n\n\n\n\n    \n      When BLUE Is Not Best: Non-Normal Errors and the Linear Model \n      \n      \n      \n      \n        \n          Jul 1, 2022. 'Kolade Gracious.\n        \n      \n         \n           Read on Quarto\n        \n         \n           Medium \n        \n         \n           GitHub Code \n        \n         \n           Twitter Post \n         \n      \n      \n      \n    \n\n\nNo matching items"
  },
  {
    "objectID": "data/index.html#data-analytics-projects",
    "href": "data/index.html#data-analytics-projects",
    "title": "'Kolade Gracious",
    "section": "",
    "text": "While Navigating…..\n\n\n\n\nAccess all data projects with the sub-links posted under each post. Report on issues, queries and clarification on Github\n\n\n\n\n\n\n\n\n\n\n    \n      Analyzing U.S Financial Aid to Africa's 7 Largest Economies [2019 - 2022] \n      \n      \n      \n        \n          Jun 26, 2023. 'Kolade Gracious.\n        \n      \n      \n         \n           LinkedIn \n         \n         \n           GitHub Code \n        \n         \n           Twitter Post \n         \n      \n      \n      \n    \n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n    \n      Returning Multi-Level Aggregates in PostgreSQL Using ROLLUP Function \n      \n      \n      \n        \n          Aug 1, 2023. 'Kolade Gracious.\n        \n      \n      \n         \n           LinkedIn \n         \n         \n           Medium \n        \n      \n      \n      \n    \n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n    \n      Creating a Comprehensive Date Table for Time Intelligence Analysis in R \n      \n      \n      \n      \n        \n          Oct 8, 2023. 'Kolade Gracious.\n        \n      \n         \n           Read on Quarto \n         \n         \n           LinkedIn \n         \n         \n           Twitter Post \n         \n      \n      \n      \n    \n    \n      The Bellabeat Case Study: Analyzing Trends in Smart Device Usage \n      \n      \n      \n      \n        \n          Dec 15, 2022. 'Kolade Gracious.\n        \n      \n         \n           Read on Kaggle \n        \n         \n           GitHub Code \n        \n      \n      \n      \n    \n\n\nNo matching items"
  },
  {
    "objectID": "data/index.html#ftr",
    "href": "data/index.html#ftr",
    "title": "'Kolade Gracious",
    "section": "Ftr",
    "text": "Ftr"
  },
  {
    "objectID": "data/projects/datetime.html",
    "href": "data/projects/datetime.html",
    "title": "Creating a Comprehensive Date Table for Time Intelligence Analysis in R",
    "section": "",
    "text": "|\nCreating a Comprehensive Date Table for Time Intelligence Analysis in R Formuating comprehesive datetime feilds in R with the {stringi}, {zoo} and {lubridate} package\nI created this post as a direct response to ……. on twitter challengng rstat users to create a comprehensive date table for the year 2023 in R. He had already quoted the post completing the same challenege using Microsift Excel. Although I am proficient in Microsoft Excel - thanks to a certification offered by the - I decided to complete this task in R.\nAs posted by ……. here’s a picture of the challenge"
  },
  {
    "objectID": "data/projects/datetime.html#getting-started-with-the-basics",
    "href": "data/projects/datetime.html#getting-started-with-the-basics",
    "title": "Creating a Comprehensive Date Table for Time Intelligence Analysis in R",
    "section": "Getting Started with the BASICS",
    "text": "Getting Started with the BASICS\n\nComprehensive date table needed for the year 2023\nFiscal years starts on July 1st\nRecognized holidays to be incorporated into the date table\nWeekends are defined as Sundays and Saturdays\nVariables and corresponding observations are to be generated automatically"
  },
  {
    "objectID": "data/projects/datetime.html#unveiling-the-artistry-to-solve-this-challeng",
    "href": "data/projects/datetime.html#unveiling-the-artistry-to-solve-this-challeng",
    "title": "Creating a Comprehensive Date Table for Time Intelligence Analysis in R",
    "section": "Unveiling the aRtistry to Solve this Challeng",
    "text": "Unveiling the aRtistry to Solve this Challeng\n\nLoad the required R packages needed fr Time Intelligence analysis\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(stringi)\nlibrary(zoo)\n\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\nDeclare fixed dependencies stored as objects first\n\n\nstart_date &lt;- as.Date(\"2023/01/01\")\nend_date &lt;- as.Date(\"2023/12/31\")\n#Fiscal year starts in July (month_number 7) every year\nfiscal_start_month = 7 \n\n##create a date matrix for recognized holidays\nholiday&lt;- as.Date(\n  \"2023/01/01\", \"2023/01/02\", \"2023/04/09\", \"2023/04/10\", \n  \"2023/04/21\", \"2023/04/24\", \"2023/06/12\", \"2023/06/28\", \n  \"2023/06/29\", \"2023/10/01\", \"2023/12/25\", \"2023/12/26\"\n  )\n\n\nCreate Date sequence automatically and store as tibble\n\n\ndate_sequence &lt;- as_tibble(seq(start_date,end_date,by = \"day\"))\n\n\nhead(date_sequence)\n\n# A tibble: 6 × 1\n  value     \n  &lt;date&gt;    \n1 2023-01-01\n2 2023-01-02\n3 2023-01-03\n4 2023-01-04\n5 2023-01-05\n6 2023-01-06\n\n\n\n\n\n\n\n\nNote\n\n\n\nGenerated date sequence is stored as 365 observations in of the variable ‘value’. This sequence will be left like this throughouth this post."
  },
  {
    "objectID": "data/projects/datetime/datetime.html",
    "href": "data/projects/datetime/datetime.html",
    "title": "Creating a Comprehensive Date Table for Time Intelligence Analysis in R",
    "section": "",
    "text": "Creating a Comprehensive Date Table for Time Intelligence Analysis in R Formulating comprehensive datetime fields in R with the {stringi}, {zoo} and {lubridate} package\nI created this post as a direct response to Malcom Okonkwo’s twitter post challenging r-lang users to create a comprehensive date table for the year 2023 in R. He solved the challenge in SQL and had quoted another post completing the same challenge using Microsoft Excel. I decided to complete this task in R.\nI mean, why not? After all, R’s flexibility with datetime manipulation is notoriously underrated.\nHere’s a picture of the challenge prompt."
  },
  {
    "objectID": "data/projects/datetime/datetime.html#getting-started-with-the-basics",
    "href": "data/projects/datetime/datetime.html#getting-started-with-the-basics",
    "title": "Creating a Comprehensive Date Table for Time Intelligence Analysis in R",
    "section": "Getting Started with the Basics",
    "text": "Getting Started with the Basics\nWhat are the task variables and problems?\n\nComprehensive date table needed for the year 2023\nFiscal year starts on July 1st\nRecognized holidays to be incorporated into the date table as listed in the prompt\nWeekends are defined as Sundays and Saturdays\nVariables and corresponding observations are to be generated automatically (of course!)"
  },
  {
    "objectID": "data/projects/datetime/datetime.html#unveiling-the-artistry-to-solve-this-challeng",
    "href": "data/projects/datetime/datetime.html#unveiling-the-artistry-to-solve-this-challeng",
    "title": "Creating a Comprehensive Date Table for Time Intelligence Analysis in R",
    "section": "Unveiling the aRtistry to Solve this Challeng",
    "text": "Unveiling the aRtistry to Solve this Challeng\n\nLoad the required R packages needed for Time Intelligence analysis\n\n\nzoo (Zeileis and Grothendieck 2005)\nstringi [(Gagolewski 2022)]\nlubridate [(Grolemund and Wickham 2011)]\ntidyverse [(Wickham et al. 2019)]\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(stringi)\nlibrary(zoo)\n\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\nDeclare fixed dependencies stored as objects first\n\n\nstart_date &lt;- as.Date(\"2023/01/01\")\nend_date &lt;- as.Date(\"2023/12/31\")\n#Fiscal year starts in July (month_number 7) every year\nfiscal_start_month = 7 \n\n##create a date matrix for recognized holidays\nholiday&lt;- as.Date(\n  \"2023/01/01\", \"2023/01/02\", \"2023/04/09\", \"2023/04/10\", \n  \"2023/04/21\", \"2023/04/24\", \"2023/06/12\", \"2023/06/28\", \n  \"2023/06/29\", \"2023/10/01\", \"2023/12/25\", \"2023/12/26\"\n  )\n\n\nCreate Date sequence automatically and store as tibble\n\n\ndate_sequence &lt;- as_tibble(seq(start_date,end_date,by = \"day\"))\n\n\nhead(date_sequence)\n\n# A tibble: 6 × 1\n  value     \n  &lt;date&gt;    \n1 2023-01-01\n2 2023-01-02\n3 2023-01-03\n4 2023-01-04\n5 2023-01-05\n6 2023-01-06\n\n\n\n\n\n\n\n\nNote\n\n\n\nGenerated date sequence is stored as 365 observations in of the variable ‘value’. This sequence will be left like this throughouth this post.\n\n\n\nMutate date_sequence to create a full date table For the sake of simplicity the sections of this stage will be splitted into three parts; Year, Quarter/Week, Fiscal Year and Weekend/Holiday wrangling\n\n\nYear\n\n\ndatetable_year &lt;- date_sequence %&gt;% \n      mutate(\n    ##Year\n    year = year(value), #date_sequence is stored in [1] as \"value\"\n    day_of_month = day(value),\n    day_of_week = stri_datetime_fields(value)$DayOfWeek,\n    day_of_week_short = format(value,\"%a\"),\n    day_of_year = stri_datetime_fields(value)$DayOfYear,\n    weekday = weekdays.Date(value),\n    month = months(value),\n    month_number = stri_datetime_fields(value)$Month,\n    month_start_date = floor_date(as.Date(value, \"%Y-%m-%d\"), unit = \"month\"),\n    month_end_date = floor_date(as.Date(value, \"%Y-%m-%d\"), unit = \"month\") \n                                                     + days_in_month(value)-1, \n    ### \"-1\" to make sure the exact end on the month is returned\n    week_of_month = paste0(\"Week \", (stri_datetime_fields(value)$WeekOfMonth)),\n    week_of_year =  paste0(\"Week \", stri_datetime_fields(value)$WeekOfYear)\n      )\n\nNow, take a look at the first part of the datetable\n\nhead(datetable_year)\n\n# A tibble: 6 × 13\n  value       year day_of_month day_of_week day_of_week_short day_of_year\n  &lt;date&gt;     &lt;dbl&gt;        &lt;int&gt;       &lt;int&gt; &lt;chr&gt;                   &lt;int&gt;\n1 2023-01-01  2023            1           1 Sun                         1\n2 2023-01-02  2023            2           2 Mon                         2\n3 2023-01-03  2023            3           3 Tue                         3\n4 2023-01-04  2023            4           4 Wed                         4\n5 2023-01-05  2023            5           5 Thu                         5\n6 2023-01-06  2023            6           6 Fri                         6\n# ℹ 7 more variables: weekday &lt;chr&gt;, month &lt;chr&gt;, month_number &lt;int&gt;,\n#   month_start_date &lt;date&gt;, month_end_date &lt;date&gt;, week_of_month &lt;chr&gt;,\n#   week_of_year &lt;chr&gt;\n\n\n\nQuarter/Week\n\n\ndatetable_qtr_wk &lt;- date_sequence %&gt;% \n      mutate(\n##Quarter/Week\n        quarter = quarters.POSIXt(value),\n        qtr_start_date = format(as.Date(as.yearqtr(value, format = \"%Y-%m-%d\")),\n                                                                  \"%d-%h-%Y\"),\n        qtr_end_date = format(as.Date(as.yearqtr(value, format = \"%Y-%m-%d\"), \n                                                     frac = 1), \"%d-%h-%Y\"),\n        week_start_date = format(floor_date(as.Date(value, \"%Y-%m-%d\"), \n                         unit = \"week\", week_start = 1), \"%a-%h-%y\"),\n        #R starts weeks on Sunday, add \"week_start=1 as an arg\" to coarse to Monday\n        week_end_date = format(floor_date(as.Date(value, \"%Y-%m-%d\"), \n                                   unit = \"week\") + 6, \"%a-%h-%y\"),\n        year_month = as.yearmon(value, \"%m-%Y\"),\n        year_qrt = as.yearqtr(value, format = \"%Y-%m-%d\")\n      )\n\nThe r chunk above create multiple qtr/wk fields using the ‘value’ variable and the functionality of the loaded R packages. A look at the second part of the date table.\n\nhead(datetable_qtr_wk)\n\n# A tibble: 6 × 8\n  value      quarter qtr_start_date qtr_end_date week_start_date week_end_date\n  &lt;date&gt;     &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;        \n1 2023-01-01 Q1      01-Jan-2023    31-Mar-2023  Mon-Dec-22      Sat-Jan-23   \n2 2023-01-02 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n3 2023-01-03 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n4 2023-01-04 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n5 2023-01-05 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n6 2023-01-06 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n# ℹ 2 more variables: year_month &lt;yearmon&gt;, year_qrt &lt;yearqtr&gt;\n\n\n\nFiscal Year\n\n\ndatetable_fiscal_yr &lt;- date_sequence %&gt;% \n      mutate(\n##Fiscal Year\n    fiscal_year = paste0(\"FY-\", ifelse(month(value) &gt;= fiscal_start_month, \n                                       year(value) + 1, year(value))),\n    fiscal_qrt = quarter(value, type= \"year.quarter\", fiscal_start = 10),\n    fiscal_quarter_start_date = format(quarter(value, type= \"date_first\", \n                                      fiscal_start = 10), \"%a-%h-%y\"),\n    fiscal_quarter_end_date = format(quarter(value, type= \"date_last\", \n                                    fiscal_start = 10), \"%a-%h-%y\")\n      )\n\nNow, a look at the fiscal years variables\n\nhead(datetable_fiscal_yr)\n\n# A tibble: 6 × 5\n  value      fiscal_year fiscal_qrt fiscal_quarter_start_date\n  &lt;date&gt;     &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;                    \n1 2023-01-01 FY-2023          2023. Sun-Jan-23               \n2 2023-01-02 FY-2023          2023. Sun-Jan-23               \n3 2023-01-03 FY-2023          2023. Sun-Jan-23               \n4 2023-01-04 FY-2023          2023. Sun-Jan-23               \n5 2023-01-05 FY-2023          2023. Sun-Jan-23               \n6 2023-01-06 FY-2023          2023. Sun-Jan-23               \n# ℹ 1 more variable: fiscal_quarter_end_date &lt;chr&gt;\n\n\n\nWeekend and Holiday\n\n\ndatetable_wknd_hol &lt;- date_sequence %&gt;% \n      mutate(\n##Weekend and Holidays\n    is_weekend = format(value, \"%u\") %in% c(6,7), #Saturday(6) $ Sunday(7)\n    is_holiday = format(value, \"%Y-%m-%d\") %in% holiday\n      )\n\nhead(datetable_wknd_hol)\n\n# A tibble: 6 × 3\n  value      is_weekend is_holiday\n  &lt;date&gt;     &lt;lgl&gt;      &lt;lgl&gt;     \n1 2023-01-01 TRUE       FALSE     \n2 2023-01-02 FALSE      FALSE     \n3 2023-01-03 FALSE      FALSE     \n4 2023-01-04 FALSE      FALSE     \n5 2023-01-05 FALSE      FALSE     \n6 2023-01-06 FALSE      FALSE     \n\n\n\nBinding all sections together Now that all sections of the date table has been created, let’s bind them all together. This automatically merges all the code chunks above and produce a complete output.\n\n\ndatetable &lt;- bind_cols(datetable_year, datetable_fiscal_yr, \n                       datetable_qtr_wk, datetable_wknd_hol,\n                       .name_repair = \"minimal\"\n                       )\n\n\nExamine the dimension, column, rows and data types for the date table.\n\n\nView date table\n\n\nview(datetable)\n\n\nExamine date table dimension\n\n\ndim(datetable)\n\n[1] 365  29\n\n\nThe code chunk above reveal [datetable] as a tibble with 365 rows (total days of the year) and 29 columns (feilds generated automatically).\n\n\n\n\nglimpse(datetable)\n\nRows: 365\nColumns: 29\n$ value                     &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ year                      &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 20…\n$ day_of_month              &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ day_of_week               &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1,…\n$ day_of_week_short         &lt;chr&gt; \"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"S…\n$ day_of_year               &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ weekday                   &lt;chr&gt; \"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", …\n$ month                     &lt;chr&gt; \"January\", \"January\", \"January\", \"January\", …\n$ month_number              &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ month_start_date          &lt;date&gt; 2023-01-01, 2023-01-01, 2023-01-01, 2023-01…\n$ month_end_date            &lt;date&gt; 2023-01-31, 2023-01-31, 2023-01-31, 2023-01…\n$ week_of_month             &lt;chr&gt; \"Week 1\", \"Week 1\", \"Week 1\", \"Week 1\", \"Wee…\n$ week_of_year              &lt;chr&gt; \"Week 1\", \"Week 1\", \"Week 1\", \"Week 1\", \"Wee…\n$ value                     &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ fiscal_year               &lt;chr&gt; \"FY-2023\", \"FY-2023\", \"FY-2023\", \"FY-2023\", …\n$ fiscal_qrt                &lt;dbl&gt; 2023.2, 2023.2, 2023.2, 2023.2, 2023.2, 2023…\n$ fiscal_quarter_start_date &lt;chr&gt; \"Sun-Jan-23\", \"Sun-Jan-23\", \"Sun-Jan-23\", \"S…\n$ fiscal_quarter_end_date   &lt;chr&gt; \"Fri-Mar-23\", \"Fri-Mar-23\", \"Fri-Mar-23\", \"F…\n$ value                     &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ quarter                   &lt;chr&gt; \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q…\n$ qtr_start_date            &lt;chr&gt; \"01-Jan-2023\", \"01-Jan-2023\", \"01-Jan-2023\",…\n$ qtr_end_date              &lt;chr&gt; \"31-Mar-2023\", \"31-Mar-2023\", \"31-Mar-2023\",…\n$ week_start_date           &lt;chr&gt; \"Mon-Dec-22\", \"Mon-Jan-23\", \"Mon-Jan-23\", \"M…\n$ week_end_date             &lt;chr&gt; \"Sat-Jan-23\", \"Sat-Jan-23\", \"Sat-Jan-23\", \"S…\n$ year_month                &lt;yearmon&gt; Jan 2023, Jan 2023, Jan 2023, Jan 2023, …\n$ year_qrt                  &lt;yearqtr&gt; 2023 Q1, 2023 Q1, 2023 Q1, 2023 Q1, 2023…\n$ value                     &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ is_weekend                &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRU…\n$ is_holiday                &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…"
  },
  {
    "objectID": "data/projects/datetime/datetime.html#unveiling-the-artistry-to-solve-this-challenge",
    "href": "data/projects/datetime/datetime.html#unveiling-the-artistry-to-solve-this-challenge",
    "title": "Creating a Comprehensive Date Table for Time Intelligence Analysis in R",
    "section": "Unveiling the aRtistry to Solve this Challenge",
    "text": "Unveiling the aRtistry to Solve this Challenge\n\nLoad the required R packages needed for Time Intelligence analysis\n\n\nzoo (Zeileis and Grothendieck 2005)\nstringi [(Gagolewski 2022)]\nlubridate [(Grolemund and Wickham 2011)]\ntidyverse [(Wickham et al. 2019)]\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(stringi)\nlibrary(zoo)\n\n\n\nDeclare fixed dependencies stored as objects first\n\n\nstart_date &lt;- as.Date(\"2023/01/01\")\nend_date &lt;- as.Date(\"2023/12/31\")\n#Fiscal year starts in July (month_number 7) every year\nfiscal_start_month = 7 \n\n##create a date matrix for recognized holidays\nholiday&lt;- as.Date(\n  \"2023/01/01\", \"2023/01/02\", \"2023/04/09\", \"2023/04/10\", \n  \"2023/04/21\", \"2023/04/24\", \"2023/06/12\", \"2023/06/28\", \n  \"2023/06/29\", \"2023/10/01\", \"2023/12/25\", \"2023/12/26\"\n  )\n\n\n\nCreate Date sequence automatically and store as a tibble\n\n\ndate_sequence &lt;- as_tibble(seq(start_date,end_date,by = \"day\"))\n\n\nhead(date_sequence)\n\n# A tibble: 6 × 1\n  value     \n  &lt;date&gt;    \n1 2023-01-01\n2 2023-01-02\n3 2023-01-03\n4 2023-01-04\n5 2023-01-05\n6 2023-01-06\n\n\n\n\n\n\n\n\nNote\n\n\n\nGenerated date sequences are stored as 365 observations of the variable value. This variable name will remain unchanged throughout this post.\n\n\n\n\nMutate date_sequence to create a full date table For the sake of simplicity the sections of this stage will be discussed in three parts; Year, Quarter/Week, Fiscal Year and Weekend/Holiday wrangling\n\n\nYear\n\n\ndatetable_year &lt;- date_sequence %&gt;% \n      mutate(\n    ##Year\n    year = year(value), #date_sequence is stored in [1] as \"value\"\n    day_of_month = day(value),\n    day_of_week = stri_datetime_fields(value)$DayOfWeek,\n    day_of_week_short = format(value,\"%a\"),\n    day_of_year = stri_datetime_fields(value)$DayOfYear,\n    weekday = weekdays.Date(value),\n    month = months(value),\n    month_number = stri_datetime_fields(value)$Month,\n    month_start_date = floor_date(as.Date(value, \"%Y-%m-%d\"), unit = \"month\"),\n    month_end_date = floor_date(as.Date(value, \"%Y-%m-%d\"), unit = \"month\") \n                                                     + days_in_month(value)-1, \n    ### \"-1\" to make sure the exact end on the month is returned\n    week_of_month = paste0(\"Week \", (stri_datetime_fields(value)$WeekOfMonth)),\n    week_of_year =  paste0(\"Week \", stri_datetime_fields(value)$WeekOfYear)\n      )\n\n\nNow, take a look at the first part of the datetable\n\nhead(datetable_year)\n\n# A tibble: 6 × 13\n  value       year day_of_month day_of_week day_of_week_short day_of_year\n  &lt;date&gt;     &lt;dbl&gt;        &lt;int&gt;       &lt;int&gt; &lt;chr&gt;                   &lt;int&gt;\n1 2023-01-01  2023            1           1 Sun                         1\n2 2023-01-02  2023            2           2 Mon                         2\n3 2023-01-03  2023            3           3 Tue                         3\n4 2023-01-04  2023            4           4 Wed                         4\n5 2023-01-05  2023            5           5 Thu                         5\n6 2023-01-06  2023            6           6 Fri                         6\n# ℹ 7 more variables: weekday &lt;chr&gt;, month &lt;chr&gt;, month_number &lt;int&gt;,\n#   month_start_date &lt;date&gt;, month_end_date &lt;date&gt;, week_of_month &lt;chr&gt;,\n#   week_of_year &lt;chr&gt;\n\n\n\n\nQuarter/Week\n\n\ndatetable_qtr_wk &lt;- date_sequence %&gt;% \n      mutate(\n##Quarter/Week\n        quarter = quarters.POSIXt(value),\n        qtr_start_date = format(as.Date(as.yearqtr(value, format = \"%Y-%m-%d\")),\n                                                                  \"%d-%h-%Y\"),\n        qtr_end_date = format(as.Date(as.yearqtr(value, format = \"%Y-%m-%d\"), \n                                                     frac = 1), \"%d-%h-%Y\"),\n        week_start_date = format(floor_date(as.Date(value, \"%Y-%m-%d\"), \n                         unit = \"week\", week_start = 1), \"%a-%h-%y\"),\n        #R starts weeks on Sunday, add \"week_start=1 as an arg\" to coarse to Monday\n        week_end_date = format(floor_date(as.Date(value, \"%Y-%m-%d\"), \n                                   unit = \"week\") + 6, \"%a-%h-%y\"),\n        year_month = as.yearmon(value, \"%m-%Y\"),\n        year_qrt = as.yearqtr(value, format = \"%Y-%m-%d\")\n      )\n\nThe r chunk above create multiple qtr/wk fields using the ‘value’ variable and the functionality of the loaded R packages. A look at the second part of the date table.\n\nhead(datetable_qtr_wk)\n\n# A tibble: 6 × 8\n  value      quarter qtr_start_date qtr_end_date week_start_date week_end_date\n  &lt;date&gt;     &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;        \n1 2023-01-01 Q1      01-Jan-2023    31-Mar-2023  Mon-Dec-22      Sat-Jan-23   \n2 2023-01-02 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n3 2023-01-03 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n4 2023-01-04 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n5 2023-01-05 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n6 2023-01-06 Q1      01-Jan-2023    31-Mar-2023  Mon-Jan-23      Sat-Jan-23   \n# ℹ 2 more variables: year_month &lt;yearmon&gt;, year_qrt &lt;yearqtr&gt;\n\n\n\n\nFiscal Year\n\n\ndatetable_fiscal_yr &lt;- date_sequence %&gt;% \n      mutate(\n##Fiscal Year\n    fiscal_year = paste0(\"FY-\", ifelse(month(value) &gt;= fiscal_start_month, \n                                       year(value) + 1, year(value))),\n    fiscal_qrt = quarter(value, type= \"year.quarter\", fiscal_start = 10),\n    fiscal_quarter_start_date = format(quarter(value, type= \"date_first\", \n                                      fiscal_start = 10), \"%a-%h-%y\"),\n    fiscal_quarter_end_date = format(quarter(value, type= \"date_last\", \n                                    fiscal_start = 10), \"%a-%h-%y\")\n      )\n\nNow, a look at the fiscal years variables\n\nhead(datetable_fiscal_yr)\n\n# A tibble: 6 × 5\n  value      fiscal_year fiscal_qrt fiscal_quarter_start_date\n  &lt;date&gt;     &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;                    \n1 2023-01-01 FY-2023          2023. Sun-Jan-23               \n2 2023-01-02 FY-2023          2023. Sun-Jan-23               \n3 2023-01-03 FY-2023          2023. Sun-Jan-23               \n4 2023-01-04 FY-2023          2023. Sun-Jan-23               \n5 2023-01-05 FY-2023          2023. Sun-Jan-23               \n6 2023-01-06 FY-2023          2023. Sun-Jan-23               \n# ℹ 1 more variable: fiscal_quarter_end_date &lt;chr&gt;\n\n\n\n\nWeekend and Holiday\n\n\ndatetable_wknd_hol &lt;- date_sequence %&gt;% \n      mutate(\n##Weekend and Holidays\n    is_weekend = format(value, \"%u\") %in% c(6,7), #Saturday(6) $ Sunday(7)\n    is_holiday = format(value, \"%Y-%m-%d\") %in% holiday\n      )\n\nhead(datetable_wknd_hol)\n\n# A tibble: 6 × 3\n  value      is_weekend is_holiday\n  &lt;date&gt;     &lt;lgl&gt;      &lt;lgl&gt;     \n1 2023-01-01 TRUE       FALSE     \n2 2023-01-02 FALSE      FALSE     \n3 2023-01-03 FALSE      FALSE     \n4 2023-01-04 FALSE      FALSE     \n5 2023-01-05 FALSE      FALSE     \n6 2023-01-06 FALSE      FALSE     \n\n\n\n\nBinding all sections together Now that all sections of the date table has been created, let’s bind them all together. This automatically merges all the code chunks above and produce a complete output.\n\n\ndatetable &lt;- bind_cols(datetable_year, datetable_fiscal_yr, \n                       datetable_qtr_wk, datetable_wknd_hol,\n                       .name_repair = \"minimal\"\n                       )\n\n\n\nExamine the dimension, column, rows and data types for the date table.\n\n\nView date table\n\n\nview(datetable)\n\n\nExamine date table dimension\n\n\ndim(datetable)\n\n[1] 365  29\n\n\nThe code chunk above reveal [datetable] as a tibble with 365 rows (total days of the year) and 29 columns (feilds generated automatically).\n\nExamine data types in date table\n\n\nglimpse(datetable)\n\nRows: 365\nColumns: 29\n$ value                     &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ year                      &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 20…\n$ day_of_month              &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ day_of_week               &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1,…\n$ day_of_week_short         &lt;chr&gt; \"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"S…\n$ day_of_year               &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ weekday                   &lt;chr&gt; \"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", …\n$ month                     &lt;chr&gt; \"January\", \"January\", \"January\", \"January\", …\n$ month_number              &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ month_start_date          &lt;date&gt; 2023-01-01, 2023-01-01, 2023-01-01, 2023-01…\n$ month_end_date            &lt;date&gt; 2023-01-31, 2023-01-31, 2023-01-31, 2023-01…\n$ week_of_month             &lt;chr&gt; \"Week 1\", \"Week 1\", \"Week 1\", \"Week 1\", \"Wee…\n$ week_of_year              &lt;chr&gt; \"Week 1\", \"Week 1\", \"Week 1\", \"Week 1\", \"Wee…\n$ value                     &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ fiscal_year               &lt;chr&gt; \"FY-2023\", \"FY-2023\", \"FY-2023\", \"FY-2023\", …\n$ fiscal_qrt                &lt;dbl&gt; 2023.2, 2023.2, 2023.2, 2023.2, 2023.2, 2023…\n$ fiscal_quarter_start_date &lt;chr&gt; \"Sun-Jan-23\", \"Sun-Jan-23\", \"Sun-Jan-23\", \"S…\n$ fiscal_quarter_end_date   &lt;chr&gt; \"Fri-Mar-23\", \"Fri-Mar-23\", \"Fri-Mar-23\", \"F…\n$ value                     &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ quarter                   &lt;chr&gt; \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q1\", \"Q…\n$ qtr_start_date            &lt;chr&gt; \"01-Jan-2023\", \"01-Jan-2023\", \"01-Jan-2023\",…\n$ qtr_end_date              &lt;chr&gt; \"31-Mar-2023\", \"31-Mar-2023\", \"31-Mar-2023\",…\n$ week_start_date           &lt;chr&gt; \"Mon-Dec-22\", \"Mon-Jan-23\", \"Mon-Jan-23\", \"M…\n$ week_end_date             &lt;chr&gt; \"Sat-Jan-23\", \"Sat-Jan-23\", \"Sat-Jan-23\", \"S…\n$ year_month                &lt;yearmon&gt; Jan 2023, Jan 2023, Jan 2023, Jan 2023, …\n$ year_qrt                  &lt;yearqtr&gt; 2023 Q1, 2023 Q1, 2023 Q1, 2023 Q1, 2023…\n$ value                     &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ is_weekend                &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRU…\n$ is_holiday                &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…"
  },
  {
    "objectID": "data/projects/datetime/datetime.html#code-block",
    "href": "data/projects/datetime/datetime.html#code-block",
    "title": "Creating a Comprehensive Date Table for Time Intelligence Analysis in R",
    "section": "Code Block",
    "text": "Code Block\nA screen grab of all r-chunk as one? Why not?"
  }
]