[
  {
    "objectID": "blogs/2023-08-18-test/index.html",
    "href": "blogs/2023-08-18-test/index.html",
    "title": "Equivalence Tests Using {marginaleffects}",
    "section": "",
    "text": "First, a bit of background on the paper and the idea of hypothesizing that a variable “has no effect.”\nI remember sitting in a talk as a first-year graduate student, and the speaker said something like: “I expect no effect here, and, just as I expected, the difference is not statistically significant.” I was a little bit taken aback—of course, that’s not a compelling argument for a null effect. But I saw this approach taken again and again in published work.\nMy first publication was an AJPS article (Rainey 2014) explaining why this doesn’t work well and how to do it better.\nHere’s what I wrote in that paper:\n\nHypothesis testing is a powerful empirical argument not because it shows that the data are consistent with the research hypothesis, but because it shows that the data are inconsistent with other hypotheses (i.e., the null hypothesis). However, researchers sometimes reverse this logic when arguing for a negligible effect, showing only that the data are consistent with “no effect” and failing to show that the data are inconsistent with meaningful effects. When researchers argue that a variable has “no effect” because its confidence interval contains zero, they take no steps to rule out large, meaningful effects, making the empirical claim considerably less persuasive (Altman and Bland 1995; Gill 1999; Nickerson 2000).\n\nBut here’s a critical point, it’s impossible to reject every hypothesis except exactly no effect. Instead, the researcher must define a range of substantively “negligible” effects. The researcher can reject the null hypothesis that the effect falls outside this range of negligible effects. However, this requires a substantive judgement about those effects that are negligible and those that are not.\nHere’s what I wrote:\n\nResearchers who wish to argue for a negligible effect must precisely define the set of effects that are deemed “negligible” as well as the set of effects that are “meaningful.” This requires defining the smallest substantively meaningful effect, which I denote as \\(m\\). The definition must be debated by substantive scholars for any given context because the appropriate \\(m\\) varies widely across applications."
  },
  {
    "objectID": "blogs/2023-08-18-test/index.html#background-on-arguing-for-a-negligible-effect",
    "href": "blogs/2023-08-18-test/index.html#background-on-arguing-for-a-negligible-effect",
    "title": "Equivalence Tests Using {marginaleffects}",
    "section": "",
    "text": "First, a bit of background on the paper and the idea of hypothesizing that a variable “has no effect.”\nI remember sitting in a talk as a first-year graduate student, and the speaker said something like: “I expect no effect here, and, just as I expected, the difference is not statistically significant.” I was a little bit taken aback—of course, that’s not a compelling argument for a null effect. But I saw this approach taken again and again in published work.\nMy first publication was an AJPS article (Rainey 2014) explaining why this doesn’t work well and how to do it better.\nHere’s what I wrote in that paper:\n\nHypothesis testing is a powerful empirical argument not because it shows that the data are consistent with the research hypothesis, but because it shows that the data are inconsistent with other hypotheses (i.e., the null hypothesis). However, researchers sometimes reverse this logic when arguing for a negligible effect, showing only that the data are consistent with “no effect” and failing to show that the data are inconsistent with meaningful effects. When researchers argue that a variable has “no effect” because its confidence interval contains zero, they take no steps to rule out large, meaningful effects, making the empirical claim considerably less persuasive (Altman and Bland 1995; Gill 1999; Nickerson 2000).\n\nBut here’s a critical point, it’s impossible to reject every hypothesis except exactly no effect. Instead, the researcher must define a range of substantively “negligible” effects. The researcher can reject the null hypothesis that the effect falls outside this range of negligible effects. However, this requires a substantive judgement about those effects that are negligible and those that are not.\nHere’s what I wrote:\n\nResearchers who wish to argue for a negligible effect must precisely define the set of effects that are deemed “negligible” as well as the set of effects that are “meaningful.” This requires defining the smallest substantively meaningful effect, which I denote as \\(m\\). The definition must be debated by substantive scholars for any given context because the appropriate \\(m\\) varies widely across applications."
  },
  {
    "objectID": "blogs/2023-08-18-test/index.html#clark-and-golder-2006",
    "href": "blogs/2023-08-18-test/index.html#clark-and-golder-2006",
    "title": "Equivalence Tests Using {marginaleffects}",
    "section": "Clark and Golder (2006)",
    "text": "Clark and Golder (2006)\nClark and Golder (2006) offer a nice example of this sort of hypothesis. I’ll refer you there and to Rainey (2014) for a complete discussion of their idea, but I’ll motivate it briefly here.\nExplaining why a country might have only a few (i.e., two) parties, Clark and Golder write:\n\nFirst, it could be the case that the demand for parties is low because there are few social cleavages. In this situation, there would be few parties whether the electoral institutions were permissive or not. Second, it could be the case that the electoral system is not permissive. In this situation, there would be a small number of parties even if the demand for political parties were high. Only a polity characterized by both a high degree of social heterogeneity and a highly permissive electoral system is expected to produce a large number of parties. (p. 683)\n\nThus, they expect that electoral institutions won’t matter in socially homogenous systems. And they expect that social heterogeneity won’t matter in electoral systems that are not permissive."
  },
  {
    "objectID": "blogs/2023-08-18-test/index.html#reproducing-clark-and-golder-2006",
    "href": "blogs/2023-08-18-test/index.html#reproducing-clark-and-golder-2006",
    "title": "Equivalence Tests Using {marginaleffects}",
    "section": "Reproducing Clark and Golder (2006)",
    "text": "Reproducing Clark and Golder (2006)\nBefore computing their specific quantities of interest, let’s reproduce their regression model. Here’s their table that we’re trying to reproduce.\n\nAnd here’s a reproduction of their estimates using the cg2006 data from the {crdata} package on GitHub.11 Run ?crdata::cg2006 for detailed documentation of this data set.\n\n# load packages\nlibrary(tidyverse)\n\n# bind the comparisons together and plot"
  },
  {
    "objectID": "blogs/index.html",
    "href": "blogs/index.html",
    "title": "Blogs",
    "section": "",
    "text": "Documenting Blogs Bordering on Medical Writing et al\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nDirect Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing\n\n\nExploring a novel innovation in genome sequencing\n\n\n\n\nCell\n\n\nSequencing\n\n\nBiotechnology\n\n\n\n\nCell-based studies are important in biotechnology. But, how can a scientist avoid the usual errors and get the best result?\n\n\n\n\n\n\nSep 18, 2023\n\n\n’Kolade Gracious\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "copies/index.html",
    "href": "copies/index.html",
    "title": "Copies",
    "section": "",
    "text": "Political Methodology\n\n\n \n\n\n\n\nJul 1, 2023\n\n\nGtyr Baissa, Locke Rainey\n\n\ngap\n\n\n2023\n\n\n../copies/gapweb/letter.pdf\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "copies/index.html#gap-analysis",
    "href": "copies/index.html#gap-analysis",
    "title": "Copies",
    "section": "",
    "text": "Political Methodology\n\n\n \n\n\n\n\nJul 1, 2023\n\n\nGtyr Baissa, Locke Rainey\n\n\ngap\n\n\n2023\n\n\n../copies/gapweb/letter.pdf\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "copies/index.html#website-copies",
    "href": "copies/index.html#website-copies",
    "title": "Copies",
    "section": "Website Copies",
    "text": "Website Copies\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data/index.html#sql-postgresql",
    "href": "data/index.html#sql-postgresql",
    "title": "Data Analysis Projects",
    "section": "SQL (PostgreSQL)",
    "text": "SQL (PostgreSQL)\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data/index.html#microsoft-excel",
    "href": "data/index.html#microsoft-excel",
    "title": "Data Analysis Projects",
    "section": "Microsoft Excel",
    "text": "Microsoft Excel\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "’Kolade Gracious",
    "section": "",
    "text": "email\n  \n  \n    \n     Resume [Med.Writer]\n  \n  \n    \n     Resume [Data Analyst]\n  \n  \n    \n     Linkedin\n  \n\n  \n  \nSince completing my first degree in Pharmacy from Nigeria’s Premier varsity, University of Ibadan, my research has appeared in the BMJC and on med. writing spaces as journal reviews, gap analysis, medical commentaries and continuing educations courses. Currently, I develop medical communication solutions in pharma, neurology, infections diseases and professional learning with deliverables designed as continuing education courses, website copies, …..\nWhen I am not writing healthcare contents, you’d find me on RStudio, Microsoft Excel or pgAdmin writing code syntaxes required for exploratory data analysis, inferential statistics, data modelling and data validation in R, SQL and DAX.\nOther times, you would probably find me somewhere in Lagos, Nigeria, discussing politics in Africa or listening to a wierd mashed-up playlist of Billie Eilish, Jacob Banks, Lana Del Rey, Burna Boy, and the Nigerian sonic-artistry maestro, Brymo Olooforo.\n\nConnect\nGot writing gigs or project collaborations for me? Sounds right! Send me a brief and let’s create magic.\n\n  \n      Send Me a Brief!\n  \n\n\nYou can find me on Twitter, Linkedin and Coursera. I publicly version-control many of my data analysis and writing projects on GitHub. You can find the repo for this Quarto website at ../koladegray/github.io\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "journals/index.html",
    "href": "journals/index.html",
    "title": "Jounals",
    "section": "",
    "text": "No matching items\n\n Back to top"
  },
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Talks",
    "section": "",
    "text": "No matching items\n\n\nDocumenting technical e-books and continuing education courses in healthcare\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blogs/2023-9-18-direct-library-preparation/index.html",
    "href": "blogs/2023-9-18-direct-library-preparation/index.html",
    "title": "Direct Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing",
    "section": "",
    "text": "Cell culture and tissue studies are becoming important in genomics and human biology. Despite the wide innovations in the field of cell studies, clinical results and experimental reviews from cell-based examinations are still largely tilted towards the conventional assumption that all cells derived from cultures and tissues are completely homogeneous.\nHow then should scientists study biological heterogeneity? Most importantly, how should they study the inherent properties of a single cell as an offshoot of the genome?"
  },
  {
    "objectID": "blogs/2023-9-18-direct-library-preparation/index.html#cell-sequencing-processes-and-studies",
    "href": "blogs/2023-9-18-direct-library-preparation/index.html#cell-sequencing-processes-and-studies",
    "title": "Direct Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing",
    "section": "Cell Sequencing Processes and Studies",
    "text": "Cell Sequencing Processes and Studies\nFor decades on end, cell biologists have devised multiple cell sequencing methods to navigate beyond the technical difficulties of cell examination. Scientific insight into cell cultures and tissues are basically important in cancer studies and cell other forms of cellular anomalies.\nSingle cell sequencing (SCS) techniques have long been considered a standard procedure in inter-cellular probing.\nWhen coupled with technological advancements in genome amplification and single cell isolation, SCS produces a valuable set in cellular studies of inherent properties at high resolution. As a leading player in the global biotechnology market, CELLINK Life Sciences offer the most accurate and effective methods employed in cell-based studies.\nCurrently, leading research centers worldwide employs Single-cell whole-genome sequencing as a routine procedure in probing intercellular genomic variations and studying single-nucleotide variations in single cells.\nDespite the innovative results produced by these methods, studying genomic variations in with precise accuracy was still a big challenge in human medicine and cell biology. Scientists are consistently burdened with many question. The chief of which is – how exactly should we qualitatively study genomic features and cell heterogeneity?"
  },
  {
    "objectID": "blogs/2023-9-18-direct-library-preparation/index.html#popular-methods-of-isolating-single-cells",
    "href": "blogs/2023-9-18-direct-library-preparation/index.html#popular-methods-of-isolating-single-cells",
    "title": "Direct Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing",
    "section": "Popular Methods of Isolating Single Cells",
    "text": "Popular Methods of Isolating Single Cells\nThe scientific race to isolate single cell from a whole genome started properly in 2009. Based on available evidence and the increasing need for cell-based studies in microbiology, scientists were able to analyze transcriptome complexity in individual cells using the first cell whole transcriptome sequencing protocol.\nThe scientific race to isolate single cell from a whole genome started properly in 2009. Based on available evidence and the increasing need for cell-based studies in microbiology, scientists were able to analyze transcriptome complexity in individual cells using the first cell whole transcriptome sequencing protocol.\nTwo years later, the science evolved and single-cell whole-genome sequencing was created. This breakthrough ushered in a new wave of scientific inquiries that led to the development of a single cell whole exome sequencing in 2012, and in 2013, a novel method of single cell epigenomic sequencing was developed.\nAs expected, the methods to isolating single cell from a whole genome were formed around these protocols. Currently, there are a few methods employed by different leading research institutions around the world in isolating single cells from cell culture or tissue mass. These methods, although effective to an extent, were with many shortcomings.\nTo a large extent, the general challenge associated with these old methods is in adequately controlling the quality and quantity of cell isolates extracted from tissues or cell cultures. These old methods include: \n\nFluorescence Activated Cell Sorting (FACS)\nMicrofluidics\nMechanical Micromanipulation\n\n\n\n1. Fluorescence Activated Cell Sorting (FACS)\n\nWith wide application in microbiology, immunology, and embryonic development, Fluorescence Activated Cell Sorting is widely used in many laboratories and genomic research facilities. A popular high point linked with FACS is the ease and efficiency with which this method can isolate multiple cells (hundreds of thousands of cells) in split timing.\n\n\n\n\nFACS\n\n\n\nThe protocol of operation of cell isolation in FACS is centered on\n\nCell size\nCell Fluorescence Properties\nCell Granularity\n\nThis method is generally considered efficient and fast as it creates a unique system of cell sorting. When in use, FACS can easily isolate designated cells from a tissue sample or genome by exploring the ability of these cells to fluorescence when pre-labeled.\nThis unique property of the FACS cell-sorting protocol explains its popularity in the study f single viral particles in a poll or assemblage of mixed viral genome. When compared with recently developed protocols, such as the Direct Library Preparation Plus, the Fluorescence Activated Cell Sorting method is limited in application.\nIn this method, it is compulsory that a bulk of the cell assemblage be prepared as sorting material and samples must be prepared in solution. Earlier observation reports also holds that the fluorescent dye used in cell labeling can damage the viability of cells or influence the inherent properties of the single cells.\n\n\n2. Microfluids\nThe shortcomings with FACS, especially the need for an abundant cell assemblage and risk of losing cell viability, led to the development of Microfluidics. This method employs a protocol setting completely different in mechanism to the FACS.\nMicrofluidics is widely used in\n\nMicrobiology\nEmbryonic development studies\nNeurobiology\n\nBasically, the Microfluidics setup uses a highly integrated system to achieve single cell culture and sequencing by manipulating small volumes of a few hundreds of micro-liters of fluids. As the nomenclature suggests, Microfluidics needs only a few volume of fluids in cell-based studies.\n\n\n\n\nMicrofluidics Setup\n\n\n\nResearch institutes from around the world are currently experimenting with the feasibility of employing Microfluidics in human medicine especially in the areas of epigenomics sequencing and single cell whole-genome studies.\nIn the laboratories and microbiological studies, Microfluidics can effectively separate biological nanoparticles from tissues samples, cell cultures and cell assemblage. In a 2016 publication of Nature, the future of Microfluidics was examined based on coverage and advantage in cell sequencing.\nReports from this review suggest that Microfluidics produces accurate results with a unique level of sensitivity in almost all research applications as reported. This method can also finely resolve nanoliter-to-picoliter volumes of samples in research studies that need timely analysis and effective outcomes in low volume fluids.\n\n\n3. Mechanical Micromanipulation\nAs an old and classic method in cell isolation and single-cell based studies, Mechanical Micromanipulation surely deserves an honorable mention. This manual method is cost-efficient and can only need cheap instrumentation especially when results are not needed to be extremely accurate.\nThis explains the continued use of Mechanical Micromanipulation in many Microbiology research laboratories around the world, despite the popularity of new methods. The Mechanical Micromanipulation setup only requires the mechanical suctioning of a single cell from a cell assemblage using a capillary pipette, microscope and other supporting instruments.\n\n\n\n\nMechanical Manipulation setup\n\n\n\nCell isolation is not automatic and as such requires personnel guidance in the visual inspection of single-cell color features and morphological characteristics. The shortcoming of Mechanical Micromanipulation is centered on its manual processes.\nRanging from personnel faults, to mechanical shearing during manipulation and the possibility of cell damage, the shortcoming of Mechanical Micromanipulation appears to be unlimited in perspective.\nAlthough, the microscope provides a means of exact cell identification in a tissue sample, an unskilled personnel might misidentify the target cell and the whole process is time-consuming. These shortcoming are solved in Microfluidics and the Fluorescence Activated Cell Sorting method"
  },
  {
    "objectID": "blogs/2023-9-18-direct-library-preparation/index.html#direct-library-preparation-method-the-latest-innovation-in-cell-sequencing",
    "href": "blogs/2023-9-18-direct-library-preparation/index.html#direct-library-preparation-method-the-latest-innovation-in-cell-sequencing",
    "title": "Direct Library Preparation: The Latest Innovation in Single-Cell Whole Genome Sequencing",
    "section": "Direct Library Preparation Method: The Latest Innovation in Cell Sequencing",
    "text": "Direct Library Preparation Method: The Latest Innovation in Cell Sequencing\nThe Direct Library Preparation method of cell sequencing was developed as a scalable single-cell whole-genome sequencing platform. Compared to other methods before this innovation, the Direct Library Preparation instrumentation is perfectly designed for accuracy, high resolution and unparalleled efficiency in cell isolation experiments and research findings.\nRecently published biotech reviews on this subject matter have positioned DLP as more than just an innovation in cell isolation studies. By large, it ushers in an era where microbiology and human medicine can optimally benefit from technology.\n\n\n\n\nDLP\n\n\n\nThe instrumentation boasts of open source computational methods, image-based object recognition and commodity instrument. This innovation is widely used in many research finding for the identification of clonal populations and their corresponding genomic features.\nDirect Library Preparation has shown useful prospects in\n\nTumor studies\nMicrobiology\nNeurology\nImmunology\nEmbryonic development studies\n\nBy extension, there are theoretical evidences supporting the use of this novel method in genome heterogeneity studies, mutational processes and findings on clonal evolution in healthy and cancer tissues. Early reviews and studies on the Direct Library Preparation platform showed that it can capture a high-resolution microscopy images of cells. These images are captured as the cells navigates a transparent nozzle as they settle in wells.\nImage output allows for exact cell identification and separation. All single cell captures are lysed processes to produce unique sequencing inserts. Standard illumina protocols and allows the researcher to pool and sequence indexed libraries at the desired coverage depth.\nThe wide application of Direct Library Preparation in the research might also be linked with the innovative advantage of the development and inclusion of an open-source, cloud compatible software infrastructure. This inclusion allows the bulk storage of data and metadata produced in all sequencing and imaging processes. Based on a researcher’s preference, the result generated from this storage can be loaded into selected data visualization and assessment platform for further studies, data exploration and quality control.\nAn early report on the application of Direct Library Preparation was published by a January 2020 issue of Nature Methods. The authors in this study use Direct Library Preparation to generate a resource of 51,926 single-cell genomes and matched cell images from diverse cell types including cell lines, xenograft and diagnostic samples with limited material. The resource bulk generated allows the study of variations in mitotic mis-segregation rates across tissues types and genotypes. As expected, the analysis of genomic matches obtained and images captured aided in establishing a correlation between cellular morphology and genome ploidy states.\nThis single review on DLP argued a case for its integration into medical sciences especially in tumor and embryonic development studies. This study, as reported, also documented the calculation of single-nucleotide resolution clonal genotypes and inferences of clonal phylogenies using aggregation of cells sharing copy number profiles. As a last result in this study, the authors also reported clone-specific chromosomal aneuploidy in polyclonal populations as defined by joint analysis of the listed features. Speculations on the readiness of DLP’s use in human medicine are currently on debate.\nHowever, there are enough evidence to argue for its usefulness in tumor studies. By allowing the measurement of clonal replication states and rare aneuploidy patterns of single cells, DLP is evidently suitable for embryonic development and tumor tracking studies.\n\nComparison, Benefits and Features\nMicrofluidics, Mechanical Micromanipulation and Fluorescence Activated Cell Sorting are methods developed early in cell isolation and single cell studies. However, the shortcoming of these methods have called for their replacement in many research studies and laboratory institutes.\nThe biggest challenge posed by these methods is that samples must be prepared in suspension and thus, the spatial location of the target cells in the tissues or cell cultures can be lost easily. Surprisingly, the Direct Library Preparation protocol is affordable and can be widely used on scalable methods in human and cellular studies.\nThis method is also widely considered a low bias method that can allow the spontaneous and in-depth analysis of variety of samples. In essence, this method can be effectively employed in genomic matching of tissues, cell assemblage and cell cultures.\n\n\nHow Direct Library Preparation Solves the Problems in Cell Sequencing\nUnlike other methods, the Direct Library Preparation method also allows the determination of copy number variations (CNV), single nucleotide polymorphisms (SNPs), phylogenic reconstructions and cluster analyses.\nThe arrays of benefits of using the DLP in research and experimental findings are limitless and include:\n\nLow reagent cost\nHigh quality of singe cell whole genome libraries\nLineage reconstructions\nUse in the analysis of any cell and nuclei from 5 to 80 micrometer.\n\nTo a large extent, DLP solved the myriads of shortcomings associated with the early methods employed in cell sequencing researches. Using the Direct Library Preparation (DLP) method in single-cell whole-genome sequencing of clinical sample is currently considered one of the best approach for cell isolation in modern biotechnology.\nThis is coming at a time when Direct Library Preparation in human medicine is increasingly becoming a topic of global scientific interest. With time, more adoption of Direct Library Preparation method is expected to be recorded in many research facilities around the world.\nEnd"
  }
]